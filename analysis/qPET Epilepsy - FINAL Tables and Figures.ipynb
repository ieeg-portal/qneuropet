{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h1>Analysis overview</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:28.891443",
     "start_time": "2017-07-21T19:54:25.816862"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "    \n",
    "# Import general modules\n",
    "import os\n",
    "import re\n",
    "from itertools import cycle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Import HTML/js libraries\n",
    "from IPython.display import display, Javascript, HTML, Math, Latex\n",
    "import jinja2\n",
    "\n",
    "# Import data science modules\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy import interp, ndimage\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import seaborn as sns\n",
    "\n",
    "# Import graphing modules\n",
    "%matplotlib inline  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Import machine learning modules\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import *\n",
    "from sklearn.decomposition import *\n",
    "import sklearn.utils\n",
    "from sklearn.utils import *\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import R - py module\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri, numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "pandas2ri.activate()\n",
    "numpy2ri.activate()\n",
    "\n",
    "def _helper(job):\n",
    "    job_iter,train,test,X1,y1,XN,yN,classifier1,classifierN = job\n",
    "    if(job_iter %1000 == 0):\n",
    "        print job_iter\n",
    "    X1_train = X1[train]\n",
    "    y1_train = y1[train]\n",
    "    X1_test = X1[test]\n",
    "    y1_test = y1[test]\n",
    "\n",
    "    XN_train = XN[train]\n",
    "    yN_train = yN[train]\n",
    "    XN_test = XN[test]\n",
    "    yN_test = yN[test]\n",
    "\n",
    "    probas_1 = classifier1.fit(X1_train, y1_train).predict_proba(X1_test)\n",
    "    probas_N = classifierN.fit(XN_train, yN_train).predict_proba(XN_test)\n",
    "\n",
    "    return [probas_1,y1_test,probas_N,yN_test,classifier1.oob_score_,classifierN.oob_score_]\n",
    "\n",
    "ssp_labels = [u'*',u'Angular Gyrus',u'Anterior Cingulate',u'Caudate', u'Cerebellar Lingual',u'Cerebellar Tonsil',u'Cingulate Gyrus',u'Culmen', u'Culmen of Vermis',u'Cuneus',u'Declive',u'Declive of Vermis', u'Extra-Nuclear',u'Fusiform Gyrus',u'Inferior Frontal Gyrus', u'Inferior Occipital Gyrus',u'Inferior Parietal Lobule', u'Inferior Semi-Lunar Lobule',u'Inferior Temporal Gyrus',u'Lingual Gyrus', u'Medial Frontal Gyrus',u'Middle Frontal Gyrus',u'Middle Occipital Gyrus', u'Middle Temporal Gyrus',u'Nodule',u'Orbital Gyrus',u'Paracentral Lobule', u'Parahippocampal Gyrus',u'Postcentral Gyrus',u'Posterior Cingulate', u'Precentral Gyrus',u'Precuneus',u'Pyramis',u'Pyramis of Vermis', u'Rectal Gyrus',u'Subcallosal Gyrus',u'Superior Frontal Gyrus', u'Superior Occipital Gyrus',u'Superior Parietal Lobule', u'Superior Temporal Gyrus',u'Supramarginal Gyrus',u'Thalamus', u'Transverse Temporal Gyrus',u'Tuber',u'Tuber of Vermis',u'Uncus',u'Uvula', u'Uvula of Vermis']\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:28.982535",
     "start_time": "2017-07-21T19:54:28.892893"
    },
    "collapsed": true,
    "level": 7
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 929\n",
    "\n",
    "# Model parameters\n",
    "NUM_BOOTSTRAPS = 5000\n",
    "max_depth = 2\n",
    "\n",
    "n_proc = 32\n",
    "pool = Pool(n_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T15:48:15.982387",
     "start_time": "2017-07-14T15:48:15.979363"
    },
    "collapsed": false,
    "level": 7,
    "scrolled": true
   },
   "source": [
    "<h1>Demographics (Table 1)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:29.186767",
     "start_time": "2017-07-21T19:54:28.984442"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demographic Feature</th>\n",
       "      <th>Complete Seizure Freedom (Engel IA)</th>\n",
       "      <th>Good Surgical Outcome (Engel IB-D)</th>\n",
       "      <th>Poor Surgical Outcome (Engel II, III, IV)</th>\n",
       "      <th>p-value (Developmental)</th>\n",
       "      <th>Complete Seizure Freedom (Engel IA)</th>\n",
       "      <th>Good Surgical Outcome (Engel IB-D)</th>\n",
       "      <th>Poor Surgical Outcome (Engel II, III, IV)</th>\n",
       "      <th>p-value (Validation)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total number of subjects</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age at surgery</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>38.45 p/m 12.01</td>\n",
       "      <td>39.19 p/m 12.14</td>\n",
       "      <td>35.35 p/m 11.09</td>\n",
       "      <td></td>\n",
       "      <td>37.10 p/m 16.03</td>\n",
       "      <td>29.01 p/m 13.49</td>\n",
       "      <td>52.93 p/m 6.92</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gender</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.628779</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.303835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Female</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Resected Regions</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.539441</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.324409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LTL</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RTL</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LFL/RFL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LPL/RPL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MRI Findings</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0667763</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.276161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lesional</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Non-Lesional</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pathology</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.842922</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.816396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HS/MTS</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gliosis</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MCD</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tumor/Vascular</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dual Pathology</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Normal/Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PET Read</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0285491</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.152833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Restricted</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Subtle</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Diffuse or Multifocal</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Normal/Not Available</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Demographic Feature Complete Seizure Freedom (Engel IA)  \\\n",
       "0   Total number of subjects                                  25   \n",
       "1             Age at surgery                                   -   \n",
       "2                          -                     38.45 p/m 12.01   \n",
       "3                     Gender                                   -   \n",
       "4                       Male                                   9   \n",
       "5                     Female                                  16   \n",
       "6           Resected Regions                                   -   \n",
       "7                        LTL                                  14   \n",
       "8                        RTL                                  11   \n",
       "9                    LFL/RFL                                   0   \n",
       "10                   LPL/RPL                                   0   \n",
       "11              MRI Findings                                   -   \n",
       "12                  Lesional                                  19   \n",
       "13              Non-Lesional                                   6   \n",
       "14                 Pathology                                   -   \n",
       "15                    HS/MTS                                  16   \n",
       "16                   Gliosis                                   6   \n",
       "17                       MCD                                   2   \n",
       "18            Tumor/Vascular                                   0   \n",
       "19            Dual Pathology                                   1   \n",
       "20      Normal/Not Available                                   0   \n",
       "21                  PET Read                                   -   \n",
       "22                Restricted                                  12   \n",
       "23                    Subtle                                   9   \n",
       "24     Diffuse or Multifocal                                   1   \n",
       "25      Normal/Not Available                                   3   \n",
       "\n",
       "   Good Surgical Outcome (Engel IB-D)  \\\n",
       "0                                  27   \n",
       "1                                   -   \n",
       "2                     39.19 p/m 12.14   \n",
       "3                                   -   \n",
       "4                                  10   \n",
       "5                                  17   \n",
       "6                                   -   \n",
       "7                                  11   \n",
       "8                                  14   \n",
       "9                                   1   \n",
       "10                                  1   \n",
       "11                                  -   \n",
       "12                                 15   \n",
       "13                                 12   \n",
       "14                                  -   \n",
       "15                                 16   \n",
       "16                                  6   \n",
       "17                                  1   \n",
       "18                                  1   \n",
       "19                                  1   \n",
       "20                                  2   \n",
       "21                                  -   \n",
       "22                                 12   \n",
       "23                                  6   \n",
       "24                                  3   \n",
       "25                                  6   \n",
       "\n",
       "   Poor Surgical Outcome (Engel II, III, IV) p-value (Developmental)  \\\n",
       "0                                         25                     NaN   \n",
       "1                                          -                     NaN   \n",
       "2                            35.35 p/m 11.09                           \n",
       "3                                          -                0.628779   \n",
       "4                                         12                       -   \n",
       "5                                         13                       -   \n",
       "6                                          -                0.539441   \n",
       "7                                         14                       -   \n",
       "8                                          8                       -   \n",
       "9                                          2                       -   \n",
       "10                                         1                       -   \n",
       "11                                         -               0.0667763   \n",
       "12                                        11                       -   \n",
       "13                                        14                       -   \n",
       "14                                         -                0.842922   \n",
       "15                                        15                       -   \n",
       "16                                         4                       -   \n",
       "17                                         2                       -   \n",
       "18                                         0                       -   \n",
       "19                                         1                       -   \n",
       "20                                         3                       -   \n",
       "21                                         -               0.0285491   \n",
       "22                                         9                       -   \n",
       "23                                         2                       -   \n",
       "24                                         9                       -   \n",
       "25                                         5                       -   \n",
       "\n",
       "   Complete Seizure Freedom (Engel IA) Good Surgical Outcome (Engel IB-D)  \\\n",
       "0                                    7                                  6   \n",
       "1                                    -                                  -   \n",
       "2                      37.10 p/m 16.03                    29.01 p/m 13.49   \n",
       "3                                    -                                  -   \n",
       "4                                    2                                  0   \n",
       "5                                    5                                  6   \n",
       "6                                    -                                  -   \n",
       "7                                    2                                  4   \n",
       "8                                    5                                  2   \n",
       "9                                    0                                  0   \n",
       "10                                   0                                  0   \n",
       "11                                   -                                  -   \n",
       "12                                   2                                  4   \n",
       "13                                   5                                  2   \n",
       "14                                   -                                  -   \n",
       "15                                   3                                  4   \n",
       "16                                   1                                  0   \n",
       "17                                   0                                  0   \n",
       "18                                   1                                  1   \n",
       "19                                   1                                  1   \n",
       "20                                   1                                  0   \n",
       "21                                   -                                  -   \n",
       "22                                   2                                  5   \n",
       "23                                   2                                  0   \n",
       "24                                   2                                  0   \n",
       "25                                   1                                  1   \n",
       "\n",
       "   Poor Surgical Outcome (Engel II, III, IV) p-value (Validation)  \n",
       "0                                          6                  NaN  \n",
       "1                                          -                  NaN  \n",
       "2                             52.93 p/m 6.92                       \n",
       "3                                          -             0.303835  \n",
       "4                                          2                    -  \n",
       "5                                          4                    -  \n",
       "6                                          -             0.324409  \n",
       "7                                          2                    -  \n",
       "8                                          2                    -  \n",
       "9                                          1                    -  \n",
       "10                                         1                    -  \n",
       "11                                         -             0.276161  \n",
       "12                                         4                    -  \n",
       "13                                         2                    -  \n",
       "14                                         -             0.816396  \n",
       "15                                         3                    -  \n",
       "16                                         0                    -  \n",
       "17                                         1                    -  \n",
       "18                                         1                    -  \n",
       "19                                         1                    -  \n",
       "20                                         0                    -  \n",
       "21                                         -             0.152833  \n",
       "22                                         2                    -  \n",
       "23                                         0                    -  \n",
       "24                                         1                    -  \n",
       "25                                         3                    -  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from printTable1 import *\n",
    "results = compute_table1()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h1>Prediction of seizure recurrence: Engel IA vs. IB-D, II-IV</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2> Feature selection </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T21:25:22.031008",
     "start_time": "2017-07-19T21:20:33.726522"
    },
    "collapsed": false,
    "level": 7,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature Selection for Model B\n",
    "\n",
    "# Parameters for feature selection\n",
    "n_repeats = 100\n",
    "num_cv = 5\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "df_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix and target vectors\n",
    "X = np.array(df[df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X_labels = np.array(df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Generate output labels\n",
    "y = np.array(df.outcomeLatest)\n",
    "y[y<2] = 0\n",
    "y[y>=2] = 1\n",
    "\n",
    "\n",
    "all_features = []\n",
    "for iter_id in range(n_repeats):\n",
    "    X_resample, y_resample = sklearn.utils.resample(X,y,n_samples=int(0.7*X.shape[0]),replace=False, random_state=RANDOM_STATE)\n",
    "    fdr = SelectKBest(f_classif,k=int(n_repeats/2))\n",
    "    fdr.fit(X_resample, y_resample)\n",
    "    for index in fdr.get_support(indices=True):\n",
    "        all_features.append(index)\n",
    "all_features =  np.sort(all_features)\n",
    "\n",
    "ft_counts = {}\n",
    "for ft in all_features:\n",
    "    try:\n",
    "        ft_counts[ft] += 1\n",
    "    except KeyError:\n",
    "        ft_counts[ft] = 1\n",
    "SSP_best_features1 = []\n",
    "for ft,ft_count in ft_counts.items():\n",
    "    if ft_count > n_repeats/2:\n",
    "        SSP_best_features1.append(ft)\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=RANDOM_STATE)\n",
    "selector = RFECV(estimator, step=1, cv=num_cv)\n",
    "selector = selector.fit(X,y)\n",
    "SSP_best_features2 = np.where(selector.support_)[0]\n",
    "\n",
    "SSP_features = list(set(SSP_best_features1) & set(SSP_best_features2))\n",
    "print sorted(SSP_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T21:37:41.874419",
     "start_time": "2017-07-19T21:25:22.032128"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "#Feature Selection for Model C\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "df_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix and target vectors\n",
    "X = np.array(df[df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X_labels = np.array(df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Generate output labels\n",
    "y = np.array(df.outcomeLatest)\n",
    "y[y<2] = 0\n",
    "y[y>=2] = 1\n",
    "\n",
    "all_features = []\n",
    "for iter_id in range(n_repeats):\n",
    "    X_resample, y_resample = sklearn.utils.resample(X,y,n_samples=int(0.7*X.shape[0]),replace=False, random_state=RANDOM_STATE)\n",
    "    fdr = SelectKBest(f_classif,k=int(n_repeats/2))\n",
    "    fdr.fit(X_resample, y_resample)\n",
    "    for index in fdr.get_support(indices=True):\n",
    "        all_features.append(index)\n",
    "all_features =  np.sort(all_features)\n",
    "\n",
    "ft_counts = {}\n",
    "for ft in all_features:\n",
    "    try:\n",
    "        ft_counts[ft] += 1\n",
    "    except KeyError:\n",
    "        ft_counts[ft] = 1\n",
    "ASYMM_best_features1 = []\n",
    "for ft,ft_count in ft_counts.items():\n",
    "    if ft_count > n_repeats/2:\n",
    "        ASYMM_best_features1.append(ft)\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=RANDOM_STATE)\n",
    "selector = RFECV(estimator, step=1, cv=num_cv)\n",
    "selector = selector.fit(X,y)\n",
    "ASYMM_best_features2 = np.where(selector.support_)[0]\n",
    "\n",
    "ASYMM_features = list(set(ASYMM_best_features1) & set(ASYMM_best_features2))\n",
    "print sorted(ASYMM_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:30.872241",
     "start_time": "2017-07-21T19:54:30.868361"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "SSP_features = [1, 5, 32, 33, 41, 44, 50, 51, 59, 83, 108, 109, 112, 117, 126, 127, 135, 136]\n",
    "ASYMM_features = [27, 42, 44, 49, 65, 73, 144, 217, 234, 236, 339, 341, 352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T11:33:10.030119",
     "start_time": "2017-07-21T11:33:10.027447"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "len(SSP_features), len(ASYMM_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Determine number of estimators</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-20T09:01:51.120252",
     "start_time": "2017-07-20T09:00:04.478303"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "yA = y\n",
    "\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "yB = y\n",
    "\n",
    "yC = y\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "\n",
    "\n",
    "min_estimators = 15\n",
    "max_estimators = 1000\n",
    "\n",
    "clfA = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfA.set_params(n_estimators=i)\n",
    "    clfA.fit(XA,yA)\n",
    "    oob_error = 1-clfA.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsA = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "clfB = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfB.set_params(n_estimators=i)\n",
    "    clfB.fit(XB,yB)\n",
    "    oob_error = 1-clfB.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsB = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "clfC = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfC.set_params(n_estimators=i)\n",
    "    clfC.fit(XC,yC)\n",
    "    oob_error = 1-clfC.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsC = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "print n_estimatorsA, n_estimatorsB, n_estimatorsC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Measure cross-validation scores</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "This section ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-20T09:16:28.982582",
     "start_time": "2017-07-20T09:16:28.869267"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "classifierA = RandomForestClassifier(n_estimators=n_estimatorsA, max_depth=max_depth, random_state=RANDOM_STATE,oob_score=True)\n",
    "classifierB = RandomForestClassifier(n_estimators=n_estimatorsB, max_depth=max_depth, random_state=RANDOM_STATE, oob_score=True)\n",
    "classifierC = RandomForestClassifier(n_estimators=n_estimatorsC, max_depth=max_depth, random_state=RANDOM_STATE, oob_score=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=NUM_BOOTSTRAPS, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print 'Generating feature matrices ...'\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T21:54:01.420979",
     "start_time": "2017-07-19T21:39:23.230737"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "columns=['Clinical Variable(s)','CV 5-Fold AUC_1','Out Of Bag (OOB1) Error',\n",
    "         'Quantitative Variables','CV 5-Fold AUC_2','Out Of Bag (OOB2) Error',\n",
    "         'AUC Difference 95% C.I.','OOB Difference 95% C.I.'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Clinical Variable(s)':[],\n",
    "     'CV 5-Fold AUC_1':[],\n",
    "     'Out Of Bag (OOB1) Error':[],\n",
    "     'Quantitative Variables':[],\n",
    "     'CV 5-Fold AUC_2':[],\n",
    "     'Out Of Bag (OOB2) Error':[],\n",
    "     'AUC Difference 95% C.I.':[],\n",
    "     'OOB Difference 95% C.I.':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "OPTIONS = {\n",
    "    1:[np.arange(20),'EEG+MRI+PET'],\n",
    "    2:[np.arange(12),'EEG'],\n",
    "    3:[np.arange(12,14),'MRI'],\n",
    "    4:[np.arange(13,20),'PET'],\n",
    "}\n",
    "\n",
    "for OPTION,(clinical_variable_idx,variables_list) in OPTIONS.items():\n",
    "    # Generate feature matrix for CLINICAL ONLY\n",
    "    XA = X1[:,clinical_variable_idx]\n",
    "    XA_labels = X1_labels[clinical_variable_idx]\n",
    "    yA = y\n",
    "\n",
    "    # Generate feature matrix for SSP alone\n",
    "    XB = X2\n",
    "    XB_labels = X2_labels\n",
    "    XB_test = X2_test\n",
    "    XB_test_labels = X2_test_labels\n",
    "    yB = y\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XB,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_B,yB_test,classifierA_oob_score_,classifierB_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprB, tprB, thresholds = roc_curve(yB_test, probas_B[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucB = auc(fprB, tprB)\n",
    "        out.append([roc_aucA,roc_aucB,classifierA_oob_score_,classifierB_oob_score_])\n",
    "    out21 = np.array(out)\n",
    "\n",
    "    # Generate feature matrix for SSP and CLINICAL\n",
    "    XB = np.hstack((X1,X2))\n",
    "    XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "    XB_test = np.hstack((X1_test,X2_test))\n",
    "    XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XB,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_B,yB_test,classifierA_oob_score_,classifierB_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprB, tprB, thresholds = roc_curve(yB_test, probas_B[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucB = auc(fprB, tprB)\n",
    "        out.append([roc_aucA,roc_aucB,classifierA_oob_score_,classifierB_oob_score_])\n",
    "    out31 = np.array(out)\n",
    "\n",
    "    # Compute statistics\n",
    "    AUC1 = np.mean(out21[:,0])\n",
    "    OOB1 = np.mean(out21[:,2])\n",
    "    AUC2 = np.mean(out21[:,1])\n",
    "    OOB2 = np.mean(out21[:,3])\n",
    "    AUC3 = np.mean(out31[:,1])\n",
    "    OOB3 = np.mean(out31[:,3])\n",
    "    CI_AUC2_minus_AUC1 = tuple(map(lambda x: np.percentile(out21[:,1] - out21[:,0],x), [2.5, 97.5]))\n",
    "    CI_AUC3_minus_AUC1 = tuple(map(lambda x: np.percentile(out31[:,1] - out31[:,0],x), [2.5, 97.5]))\n",
    "    CI_OOB2_minus_OOB1 = tuple(map(lambda x: np.percentile(out21[:,3] - out21[:,2],x), [2.5, 97.5]))\n",
    "    CI_OOB3_minus_OOB1 = tuple(map(lambda x: np.percentile(out31[:,3] - out31[:,2],x), [2.5, 97.5]))\n",
    "\n",
    "\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [variables_list,AUC1,OOB1,'%s+SSP'%(variables_list), AUC2, OOB2, CI_AUC2_minus_AUC1, CI_OOB2_minus_OOB1],\n",
    "                [variables_list,AUC1,OOB1,'SSP only', AUC3, OOB3, CI_AUC3_minus_AUC1, CI_OOB3_minus_OOB1]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.021917",
     "start_time": "2017-07-19T21:54:01.422075"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "columns=['Clinical Variable(s)','CV 5-Fold AUC_1','Out Of Bag (OOB1) Error',\n",
    "         'Quantitative Variables','CV 5-Fold AUC_2','Out Of Bag (OOB2) Error',\n",
    "         'AUC Difference 95% C.I.','OOB Difference 95% C.I.'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Clinical Variable(s)':[],\n",
    "     'CV 5-Fold AUC_1':[],\n",
    "     'Out Of Bag (OOB1) Error':[],\n",
    "     'Quantitative Variables':[],\n",
    "     'CV 5-Fold AUC_2':[],\n",
    "     'Out Of Bag (OOB2) Error':[],\n",
    "     'AUC Difference 95% C.I.':[],\n",
    "     'OOB Difference 95% C.I.':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "OPTIONS = {\n",
    "    1:[np.arange(20),'EEG+MRI+PET'],\n",
    "    2:[np.arange(12),'EEG'],\n",
    "    3:[np.arange(12,14),'MRI'],\n",
    "    4:[np.arange(13,20),'PET'],\n",
    "}\n",
    "\n",
    "for OPTION,(clinical_variable_idx,variables_list) in OPTIONS.items():\n",
    "    # Generate feature matrix for CLINICAL ONLY\n",
    "    XA = X1[:,clinical_variable_idx]\n",
    "    XA_labels = X1_labels[clinical_variable_idx]\n",
    "    yA = y\n",
    "\n",
    "    # Generate feature matrix for SSP alone\n",
    "    XC = X3\n",
    "    XC_labels = X3_labels\n",
    "    XC_test = X3_test\n",
    "    XC_test_labels = X3_test_labels\n",
    "    yC = y\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XC,yC,classifierA,classifierC))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_C,yC_test,classifierA_oob_score_,classifierC_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprC, tprC, thresholds = roc_curve(yC_test, probas_C[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucC = auc(fprC, tprC)\n",
    "        out.append([roc_aucA,roc_aucC,classifierA_oob_score_,classifierC_oob_score_])\n",
    "    out21 = np.array(out)\n",
    "\n",
    "    # Generate feature matrix for SSP and CLINICAL\n",
    "    XC = np.hstack((X1,X3))\n",
    "    XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "    XC_test = np.hstack((X1_test,X3_test))\n",
    "    XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XC,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_C,yC_test,classifierA_oob_score_,classifierC_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprC, tprC, thresholds = roc_curve(yC_test, probas_C[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucC = auc(fprC, tprC)\n",
    "        out.append([roc_aucA,roc_aucC,classifierA_oob_score_,classifierC_oob_score_])\n",
    "    out31 = np.array(out)\n",
    "\n",
    "    # Compute statistics\n",
    "    AUC1 = np.mean(out21[:,0])\n",
    "    OOB1 = np.mean(out21[:,2])\n",
    "    AUC2 = np.mean(out21[:,1])\n",
    "    OOB2 = np.mean(out21[:,3])\n",
    "    AUC3 = np.mean(out31[:,1])\n",
    "    OOB3 = np.mean(out31[:,3])\n",
    "    CI_AUC2_minus_AUC1 = tuple(map(lambda x: np.percentile(out21[:,1] - out21[:,0],x), [2.5, 97.5]))\n",
    "    CI_AUC3_minus_AUC1 = tuple(map(lambda x: np.percentile(out31[:,1] - out31[:,0],x), [2.5, 97.5]))\n",
    "    CI_OOB2_minus_OOB1 = tuple(map(lambda x: np.percentile(out21[:,3] - out21[:,2],x), [2.5, 97.5]))\n",
    "    CI_OOB3_minus_OOB1 = tuple(map(lambda x: np.percentile(out31[:,3] - out31[:,2],x), [2.5, 97.5]))\n",
    "\n",
    "\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [variables_list,AUC1,OOB1,'%s+Asymmetry'%(variables_list), AUC2, OOB2, CI_AUC2_minus_AUC1, CI_OOB2_minus_OOB1],\n",
    "                [variables_list,AUC1,OOB1,'Asymmetry only', AUC3, OOB3, CI_AUC3_minus_AUC1, CI_OOB3_minus_OOB1]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Feature Importances (Table 3)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:38.015531",
     "start_time": "2017-07-21T19:54:37.857791"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "# Create feature matrix for training and testing\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "# outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "# y[y<outcome_threshold] = 0\n",
    "# y[y>=outcome_threshold] = 1\n",
    "# y_test[y_test<outcome_threshold] = 0\n",
    "# y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "# Run predictions\n",
    "# Generate feature matrix for CLINICAL ONLY\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "XA_test = X1_test\n",
    "XA_test_labels = X1_test_labels\n",
    "yA = y\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "XB_test = np.hstack((X1_test,X2_test))\n",
    "XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "yB = y\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "XC_test = np.hstack((X1_test,X3_test))\n",
    "XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "yC = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:42.864163",
     "start_time": "2017-07-21T19:54:39.379651"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gdrive/public/USERS/lkini/thesis/ec2/anaconda2/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: randomForest 4.6-12\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/gdrive/public/USERS/lkini/thesis/ec2/anaconda2/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/gdrive/public/USERS/lkini/thesis/ec2/anaconda2/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Loading required package: MASS\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/gdrive/public/USERS/lkini/thesis/ec2/anaconda2/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Waiting for profiling to be done...\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature Importance</th>\n",
       "      <th>Univariate Odds Ratio per Unit\n",
       " Increase in Seizure Recurrence [95% CI, p]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petclass_S</td>\n",
       "      <td>10.04</td>\n",
       "      <td>0.29 [0.10 - 0.77, 0.016 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eeg_D</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.56 [0.76 - 17.79, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eeg_LTL+</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3.00 [0.72 - 12.90, 0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eeg_RTL+</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.40 [0.05 - 2.59, 0.33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petclass_M</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.36 [1.16 - 10.00, 0.026 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>petclass_R</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.71 [0.32 - 1.60, 0.41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lesional_NL</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.35 [1.04 - 5.39, 0.041 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eeg_LTL+</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.00 [0.72 - 12.90, 0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ipsi_z_ai_3dssp_Angular Gyrus</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.53 [0.33 - 0.82, 0.006 **]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>contra_z_ai_3dssp_Angular Gyrus</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.89 [1.22 - 3.02, 0.006 **]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>eeg_D</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.56 [0.76 - 17.79, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ipsi_z_ai_3dssp_Inferior Parietal Lobule</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.36 [0.89 - 2.12, 0.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>contra_z_3dssp_Inferior Temporal Gyrus</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.03 [0.90 - 1.17, 0.65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>contra_z_ai_3dssp_Orbital Gyrus</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.92 [0.59 - 1.43, 0.71]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>contra_z_3dssp_Fusiform Gyrus</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.06 [0.89 - 1.27, 0.50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>contra_z_ai_3dssp_Precentral Gyrus</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.76 [0.46 - 1.23, 0.26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>petclass_S</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.29 [0.10 - 0.77, 0.016 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eeg_RTL+</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.40 [0.05 - 2.59, 0.33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>contra_z_ai_3dssp_Thalamus</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73 [0.46 - 1.16, 0.18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ipsi_z_ai_3dssp_Precentral Gyrus</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.32 [0.81 - 2.18, 0.26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>petclass_M</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3.36 [1.16 - 10.00, 0.026 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>eeg_RTL</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68 [0.29 - 1.57, 0.37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ipsi_voxel_ai_paracentral lobule</td>\n",
       "      <td>5.46</td>\n",
       "      <td>0.00 [0.00 - 0.29, 0.027 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>contra_region_ai_posterior cingulate gyrus</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.50 [1.01 - 2.26, 0.045 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>petclass_S</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.29 [0.10 - 0.77, 0.016 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ipsi_pet_ai_supramarginal gyrus</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.04 [0.00 - 0.97, 0.055 .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>contra_pet_ai_supramarginal gyrus</td>\n",
       "      <td>2.35</td>\n",
       "      <td>26.43 [1.03 - 1092.25, 0.055 .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ipsi_voxel_ai_inferior parietal lobule</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.02 [0.00 - 0.45, 0.019 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>eeg_D</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.56 [0.76 - 17.79, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>contra_region_ai_middle temporal gyrus</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.61 [0.98 - 2.67, 0.060 .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>contra_pet_ai_postcentral gyrus</td>\n",
       "      <td>1.29</td>\n",
       "      <td>107.85 [0.08 - 207482.39, 0.20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>contra_voxel_ai_gyrus rectus</td>\n",
       "      <td>1.28</td>\n",
       "      <td>315.11 [0.10 - 1858170.76, 0.17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>petclass_M</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.36 [1.16 - 10.00, 0.026 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lesional_L</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43 [0.19 - 0.96, 0.041 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>eeg_LTL+</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3.00 [0.72 - 12.90, 0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>eeg_RTL+</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.40 [0.05 - 2.59, 0.33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>eeg_NotAvailable</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.18 [0.13 - 8.64, 0.87]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lesional_NL</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.35 [1.04 - 5.39, 0.041 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ipsi_pet_ai_transverse temporal gyri</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04 [0.00 - 3.88, 0.17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Feature Feature Importance  \\\n",
       "0                                   petclass_S              10.04   \n",
       "1                                        eeg_D               5.28   \n",
       "2                                     eeg_LTL+               4.89   \n",
       "3                                     eeg_RTL+               4.82   \n",
       "4                                   petclass_M               3.61   \n",
       "5                                   petclass_R               2.02   \n",
       "6                                  lesional_NL               1.08   \n",
       "7                                                                   \n",
       "8                                     eeg_LTL+               4.02   \n",
       "9                ipsi_z_ai_3dssp_Angular Gyrus               3.96   \n",
       "10             contra_z_ai_3dssp_Angular Gyrus               3.75   \n",
       "11                                       eeg_D               3.27   \n",
       "12    ipsi_z_ai_3dssp_Inferior Parietal Lobule               2.90   \n",
       "13      contra_z_3dssp_Inferior Temporal Gyrus               2.60   \n",
       "14             contra_z_ai_3dssp_Orbital Gyrus               2.50   \n",
       "15               contra_z_3dssp_Fusiform Gyrus               2.12   \n",
       "16          contra_z_ai_3dssp_Precentral Gyrus               2.07   \n",
       "17                                  petclass_S               1.98   \n",
       "18                                    eeg_RTL+               1.07   \n",
       "19                  contra_z_ai_3dssp_Thalamus               0.77   \n",
       "20            ipsi_z_ai_3dssp_Precentral Gyrus               0.62   \n",
       "21                                  petclass_M               0.43   \n",
       "22                                     eeg_RTL               0.02   \n",
       "23                                                                  \n",
       "24            ipsi_voxel_ai_paracentral lobule               5.46   \n",
       "25  contra_region_ai_posterior cingulate gyrus               3.19   \n",
       "26                                  petclass_S               3.15   \n",
       "27             ipsi_pet_ai_supramarginal gyrus               2.83   \n",
       "28           contra_pet_ai_supramarginal gyrus               2.35   \n",
       "29      ipsi_voxel_ai_inferior parietal lobule               2.34   \n",
       "30                                       eeg_D               2.05   \n",
       "31      contra_region_ai_middle temporal gyrus               1.90   \n",
       "32             contra_pet_ai_postcentral gyrus               1.29   \n",
       "33                contra_voxel_ai_gyrus rectus               1.28   \n",
       "34                                  petclass_M               0.90   \n",
       "35                                  lesional_L               0.88   \n",
       "36                                    eeg_LTL+               0.87   \n",
       "37                                    eeg_RTL+               0.55   \n",
       "38                            eeg_NotAvailable               0.54   \n",
       "39                                 lesional_NL               0.42   \n",
       "40        ipsi_pet_ai_transverse temporal gyri               0.13   \n",
       "41                                                                  \n",
       "\n",
       "   Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]  \n",
       "0                         0.29 [0.10 - 0.77, 0.016 *]                           \n",
       "1                           3.56 [0.76 - 17.79, 0.11]                           \n",
       "2                           3.00 [0.72 - 12.90, 0.13]                           \n",
       "3                            0.40 [0.05 - 2.59, 0.33]                           \n",
       "4                        3.36 [1.16 - 10.00, 0.026 *]                           \n",
       "5                            0.71 [0.32 - 1.60, 0.41]                           \n",
       "6                         2.35 [1.04 - 5.39, 0.041 *]                           \n",
       "7                                                                               \n",
       "8                           3.00 [0.72 - 12.90, 0.13]                           \n",
       "9                        0.53 [0.33 - 0.82, 0.006 **]                           \n",
       "10                       1.89 [1.22 - 3.02, 0.006 **]                           \n",
       "11                          3.56 [0.76 - 17.79, 0.11]                           \n",
       "12                           1.36 [0.89 - 2.12, 0.16]                           \n",
       "13                           1.03 [0.90 - 1.17, 0.65]                           \n",
       "14                           0.92 [0.59 - 1.43, 0.71]                           \n",
       "15                           1.06 [0.89 - 1.27, 0.50]                           \n",
       "16                           0.76 [0.46 - 1.23, 0.26]                           \n",
       "17                        0.29 [0.10 - 0.77, 0.016 *]                           \n",
       "18                           0.40 [0.05 - 2.59, 0.33]                           \n",
       "19                           0.73 [0.46 - 1.16, 0.18]                           \n",
       "20                           1.32 [0.81 - 2.18, 0.26]                           \n",
       "21                       3.36 [1.16 - 10.00, 0.026 *]                           \n",
       "22                           0.68 [0.29 - 1.57, 0.37]                           \n",
       "23                                                                              \n",
       "24                        0.00 [0.00 - 0.29, 0.027 *]                           \n",
       "25                        1.50 [1.01 - 2.26, 0.045 *]                           \n",
       "26                        0.29 [0.10 - 0.77, 0.016 *]                           \n",
       "27                        0.04 [0.00 - 0.97, 0.055 .]                           \n",
       "28                    26.43 [1.03 - 1092.25, 0.055 .]                           \n",
       "29                        0.02 [0.00 - 0.45, 0.019 *]                           \n",
       "30                          3.56 [0.76 - 17.79, 0.11]                           \n",
       "31                        1.61 [0.98 - 2.67, 0.060 .]                           \n",
       "32                    107.85 [0.08 - 207482.39, 0.20]                           \n",
       "33                   315.11 [0.10 - 1858170.76, 0.17]                           \n",
       "34                       3.36 [1.16 - 10.00, 0.026 *]                           \n",
       "35                        0.43 [0.19 - 0.96, 0.041 *]                           \n",
       "36                          3.00 [0.72 - 12.90, 0.13]                           \n",
       "37                           0.40 [0.05 - 2.59, 0.33]                           \n",
       "38                           1.18 [0.13 - 8.64, 0.87]                           \n",
       "39                        2.35 [1.04 - 5.39, 0.041 *]                           \n",
       "40                           0.04 [0.00 - 3.88, 0.17]                           \n",
       "41                                                                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "robjects.globalenv['RANDOM_STATE'] = RANDOM_STATE\n",
    "\n",
    "# Generate final form of Table 2\n",
    "columns=[\n",
    "    'Feature',\n",
    "    'Feature Importance',\n",
    "    'Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Feature':[],\n",
    "     'Feature Importance':[],\n",
    "     'Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "for X,y, X_labels in [(XA,yA,XA_labels), (XB,yB,XB_labels), (XC,yC,XC_labels)]:\n",
    "    # Run feature importance (IncMSE) for random forests\n",
    "    robjects.globalenv['X'] = X\n",
    "    robjects.globalenv['y'] = y\n",
    "    summary = robjects.r['summary']\n",
    "\n",
    "    robjects.r('''\n",
    "        set.seed(RANDOM_STATE)\n",
    "        library(randomForest)        \n",
    "        rf <- randomForest(y ~ ., data=X, importance=TRUE)\n",
    "        X_importances <- importance(rf)    \n",
    "    ''')\n",
    "    X_importances = robjects.r['X_importances']\n",
    "    feature_order = np.argsort(-X_importances[:,0])\n",
    "\n",
    "    # Run univariate odds ratio computation\n",
    "    for feature in feature_order:\n",
    "        robjects.globalenv['feature'] = X[:,feature]    \n",
    "        robjects.r('''        \n",
    "            set.seed(RANDOM_STATE)\n",
    "            require(MASS)        \n",
    "            myfit <- polr(as.factor(y) ~ feature, Hess=TRUE)\n",
    "            (ctable <- coef(summary(myfit)))            \n",
    "            p <- pnorm(abs(ctable[,\"t value\"]), lower.tail=FALSE)*2\n",
    "            (ctable <- cbind(ctable, \"p value\" = p))\n",
    "            (ci <- confint(myfit))\n",
    "            myfit_ci <-exp(cbind(OR = coef(myfit), ci))            \n",
    "        ''')\n",
    "        myfit = robjects.r['myfit']\n",
    "        myfit_ci = robjects.r['myfit_ci']\n",
    "        pval = robjects.r['p'][0]\n",
    "        label = X_labels[feature]\n",
    "        try:\n",
    "            label = label.replace(label.split('_')[-1],ssp_labels[int(label.split('_')[-1])])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if X_importances[feature,0] <= 0.0:\n",
    "            continue\n",
    "        \n",
    "        if pval < 0.001:\n",
    "            pval = '%0.3f ***'%pval\n",
    "        elif pval < 0.01:\n",
    "            pval = '%0.3f **'%pval\n",
    "        elif pval < 0.05:\n",
    "            pval = '%0.3f *'%pval\n",
    "        elif pval < 0.1:\n",
    "            pval = '%0.3f .'%pval\n",
    "        else:\n",
    "            pval = '%0.2f'%pval\n",
    "        \n",
    "        results = results.append(\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    [\n",
    "                        label,\n",
    "                        '%0.2f'%X_importances[feature,0], \n",
    "                        '%0.2f [%0.2f - %0.2f, %s]'%(\n",
    "                            myfit_ci[0,0],\n",
    "                            myfit_ci[0,1], myfit_ci[1,1], \n",
    "                            pval\n",
    "                        )\n",
    "                    ]\n",
    "                ],\n",
    "                columns=columns\n",
    "            ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [\n",
    "                    '',\n",
    "                    '', \n",
    "                    ''\n",
    "                ]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "# cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "# results.style.background_gradient(cmap=cm,high=1.0,low=0.0)\n",
    "display(results)\n",
    "results.to_csv('results_Section3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Validation on testing set (Table 4)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.393784",
     "start_time": "2017-07-20T01:20:49.125Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "# Create feature matrix for training and testing\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "# Run predictions\n",
    "# Generate feature matrix for CLINICAL ONLY\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "XA_test = X1_test\n",
    "XA_test_labels = X1_test_labels\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "XB_test = np.hstack((X1_test,X2_test))\n",
    "XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "XC_test = np.hstack((X1_test,X3_test))\n",
    "XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "\n",
    "# Load library in R\n",
    "pROC = importr('pROC')\n",
    "\n",
    "# Train classifier and apply to validation test set\n",
    "classifierA = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsA, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "classifierB = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsB, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "classifierC = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsC, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "\n",
    "probas = classifierA.fit(XA, y).predict_proba(XA_test)\n",
    "predsA = robjects.FloatVector(probas[:,1])\n",
    "labelsA = robjects.IntVector(y_test)\n",
    "probas = classifierB.fit(XB, y).predict_proba(XB_test)\n",
    "predsB = robjects.FloatVector(probas[:,1])\n",
    "labelsB = robjects.IntVector(y_test)\n",
    "probas = classifierC.fit(XC, y).predict_proba(XC_test)\n",
    "predsC = robjects.FloatVector(probas[:,1])\n",
    "labelsC = robjects.IntVector(y_test)\n",
    "\n",
    "\n",
    "# Copy from python workspace to R workspace\n",
    "robjects.globalenv[\"predsA\"] = predsA\n",
    "robjects.globalenv[\"labelsA\"] = labelsA\n",
    "robjects.globalenv[\"predsB\"] = predsB\n",
    "robjects.globalenv[\"labelsB\"] = labelsB\n",
    "robjects.globalenv[\"predsC\"] = predsC\n",
    "robjects.globalenv[\"labelsC\"] = labelsC\n",
    "\n",
    "# Run pROC.roc and pROC.roc.test in R\n",
    "robjects.r('''\n",
    "    predsA<-as.numeric(unlist(predsA))\n",
    "    labelsA<-as.numeric(unlist(labelsA))\n",
    "    predsB<-as.numeric(unlist(predsB))\n",
    "    labelsB<-as.numeric(unlist(labelsB))\n",
    "    predsC<-as.numeric(unlist(predsC))\n",
    "    labelsC<-as.numeric(unlist(labelsC))\n",
    "\n",
    "    library(pROC)\n",
    "    \n",
    "    roc1 <- roc(labelsA, predsA, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc2 <- roc(labelsB, predsB, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc3 <- roc(labelsC, predsC, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc_test12<-roc.test(roc1,roc2)\n",
    "    roc_test13<-roc.test(roc1,roc3)\n",
    "    test_accuracy1<-coords(roc1, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "    test_accuracy2<-coords(roc2, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "    test_accuracy3<-coords(roc3, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "''')\n",
    "\n",
    "# Generate final form of Table 4 \n",
    "columns=['Model','AUC','Accuracy','Sensitivity','Specificity','p-value'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Model':[],\n",
    "     'AUC':[],\n",
    "     'Accuracy':[],\n",
    "     'Sensitivity':[],\n",
    "     'Specificity':[],\n",
    "     'p-value':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "results = results.append(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                'Model 1',\n",
    "                robjects.r[\"roc1\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy1\"][2],\n",
    "                robjects.r[\"test_accuracy1\"][1],\n",
    "                robjects.r[\"test_accuracy1\"][0],\n",
    "                np.nan\n",
    "            ],\n",
    "            [\n",
    "                'Model 2',\n",
    "                robjects.r[\"roc2\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy2\"][2],\n",
    "                robjects.r[\"test_accuracy2\"][1],\n",
    "                robjects.r[\"test_accuracy2\"][0],\n",
    "                robjects.r[\"roc_test12\"].rx2('p.value')[0]\n",
    "            ],\n",
    "            [\n",
    "                'Model 3',\n",
    "                robjects.r[\"roc3\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy3\"][2],\n",
    "                robjects.r[\"test_accuracy3\"][1],\n",
    "                robjects.r[\"test_accuracy3\"][0],\n",
    "                robjects.r[\"roc_test13\"].rx2('p.value')[0]\n",
    "            ]\n",
    "        ],\n",
    "        columns=columns\n",
    "    ),\n",
    "    ignore_index=True\n",
    ")\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0,low=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h1>Prediction of poor surgical outcome: Engel I vs. II-IV</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Feature selection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.394212",
     "start_time": "2017-07-20T01:20:51.859Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "#Feature Selection for Model B\n",
    "\n",
    "# Parameters for feature selection\n",
    "n_repeats = 100\n",
    "num_cv = 5\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "df_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix and target vectors\n",
    "X = np.array(df[df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X_labels = np.array(df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Generate output labels\n",
    "y = np.array(df.outcomeLatest)\n",
    "y[y<5] = 0\n",
    "y[y>=5] = 1\n",
    "\n",
    "\n",
    "all_features = []\n",
    "for iter_id in range(n_repeats):\n",
    "    X_resample, y_resample = sklearn.utils.resample(X,y,n_samples=int(0.7*X.shape[0]),replace=False, random_state=RANDOM_STATE)\n",
    "    fdr = SelectKBest(f_classif,k=int(n_repeats/2))\n",
    "    fdr.fit(X_resample, y_resample)\n",
    "    for index in fdr.get_support(indices=True):\n",
    "        all_features.append(index)\n",
    "all_features =  np.sort(all_features)\n",
    "\n",
    "ft_counts = {}\n",
    "for ft in all_features:\n",
    "    try:\n",
    "        ft_counts[ft] += 1\n",
    "    except KeyError:\n",
    "        ft_counts[ft] = 1\n",
    "SSP_best_features1 = []\n",
    "for ft,ft_count in ft_counts.items():\n",
    "    if ft_count > n_repeats/2:\n",
    "        SSP_best_features1.append(ft)\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=RANDOM_STATE)\n",
    "selector = RFECV(estimator, step=1, cv=num_cv)\n",
    "selector = selector.fit(X,y)\n",
    "SSP_best_features2 = np.where(selector.support_)[0]\n",
    "\n",
    "SSP_features = list(set(SSP_best_features1) & set(SSP_best_features2))\n",
    "print sorted(SSP_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.394599",
     "start_time": "2017-07-20T01:20:52.697Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "#Feature Selection for Model C\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "df_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix and target vectors\n",
    "X = np.array(df[df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X_labels = np.array(df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Generate output labels\n",
    "y = np.array(df.outcomeLatest)\n",
    "y[y<5] = 0\n",
    "y[y>=5] = 1\n",
    "\n",
    "all_features = []\n",
    "for iter_id in range(n_repeats):\n",
    "    X_resample, y_resample = sklearn.utils.resample(X,y,n_samples=int(0.7*X.shape[0]),replace=False, random_state=RANDOM_STATE)\n",
    "    fdr = SelectKBest(f_classif,k=int(n_repeats/2))\n",
    "    fdr.fit(X_resample, y_resample)\n",
    "    for index in fdr.get_support(indices=True):\n",
    "        all_features.append(index)\n",
    "all_features =  np.sort(all_features)\n",
    "\n",
    "ft_counts = {}\n",
    "for ft in all_features:\n",
    "    try:\n",
    "        ft_counts[ft] += 1\n",
    "    except KeyError:\n",
    "        ft_counts[ft] = 1\n",
    "ASYMM_best_features1 = []\n",
    "for ft,ft_count in ft_counts.items():\n",
    "    if ft_count > n_repeats/2:\n",
    "        ASYMM_best_features1.append(ft)\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=RANDOM_STATE)\n",
    "selector = RFECV(estimator, step=1, cv=num_cv)\n",
    "selector = selector.fit(X,y)\n",
    "ASYMM_best_features2 = np.where(selector.support_)[0]\n",
    "\n",
    "ASYMM_features = list(set(ASYMM_best_features1) & set(ASYMM_best_features2))\n",
    "print sorted(ASYMM_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:49.172363",
     "start_time": "2017-07-21T19:54:49.165757"
    },
    "collapsed": true,
    "level": 7
   },
   "outputs": [],
   "source": [
    "SSP_features = [0, 4, 6, 14, 15, 16, 18, 19, 20, 21, 22, 28, 29, 32, 36, 37, 43, 51, 52, 59, 60, 62, 78, 81, 82, 84, 85, 96, 97, 98, 105, 108, 112, 113, 119, 127, 128, 135, 136, 138, 140, 141, 142, 143]\n",
    "ASYMM_features = [43, 235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T11:34:31.389365",
     "start_time": "2017-07-21T11:34:31.386703"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(SSP_features), len(ASYMM_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Determine number of estimators</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.395027",
     "start_time": "2017-07-20T01:20:54.221Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 5 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "yA = y\n",
    "\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "yB = y\n",
    "\n",
    "yC = y\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "\n",
    "\n",
    "min_estimators = 15\n",
    "max_estimators = 1000\n",
    "\n",
    "clfA = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfA.set_params(n_estimators=i)\n",
    "    clfA.fit(XA,yA)\n",
    "    oob_error = 1-clfA.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsA = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "clfB = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfB.set_params(n_estimators=i)\n",
    "    clfB.fit(XB,yB)\n",
    "    oob_error = 1-clfB.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsB = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "clfC = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfC.set_params(n_estimators=i)\n",
    "    clfC.fit(XC,yC)\n",
    "    oob_error = 1-clfC.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsC = int(nest[np.where(err == np.min(err))[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Measure cross-validation scores</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "This section ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.395434",
     "start_time": "2017-07-20T01:20:56.573Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "classifierA = RandomForestClassifier(n_estimators=n_estimatorsA, max_depth=max_depth, random_state=RANDOM_STATE,oob_score=True)\n",
    "classifierB = RandomForestClassifier(n_estimators=n_estimatorsB, max_depth=max_depth, random_state=RANDOM_STATE, oob_score=True)\n",
    "classifierC = RandomForestClassifier(n_estimators=n_estimatorsC, max_depth=max_depth, random_state=RANDOM_STATE, oob_score=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=NUM_BOOTSTRAPS, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print 'Generating feature matrices ...'\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 5 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.395855",
     "start_time": "2017-07-20T01:20:57.201Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "columns=['Clinical Variable(s)','CV 5-Fold AUC_1','Out Of Bag (OOB1) Error',\n",
    "         'Quantitative Variables','CV 5-Fold AUC_2','Out Of Bag (OOB2) Error',\n",
    "         'AUC Difference 95% C.I.','OOB Difference 95% C.I.'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Clinical Variable(s)':[],\n",
    "     'CV 5-Fold AUC_1':[],\n",
    "     'Out Of Bag (OOB1) Error':[],\n",
    "     'Quantitative Variables':[],\n",
    "     'CV 5-Fold AUC_2':[],\n",
    "     'Out Of Bag (OOB2) Error':[],\n",
    "     'AUC Difference 95% C.I.':[],\n",
    "     'OOB Difference 95% C.I.':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "OPTIONS = {\n",
    "    1:[np.arange(20),'EEG+MRI+PET'],\n",
    "    2:[np.arange(12),'EEG'],\n",
    "    3:[np.arange(12,14),'MRI'],\n",
    "    4:[np.arange(13,20),'PET'],\n",
    "}\n",
    "\n",
    "for OPTION,(clinical_variable_idx,variables_list) in OPTIONS.items():\n",
    "    # Generate feature matrix for CLINICAL ONLY\n",
    "    XA = X1[:,clinical_variable_idx]\n",
    "    XA_labels = X1_labels[clinical_variable_idx]\n",
    "    yA = y\n",
    "\n",
    "    # Generate feature matrix for SSP alone\n",
    "    XB = X2\n",
    "    XB_labels = X2_labels\n",
    "    XB_test = X2_test\n",
    "    XB_test_labels = X2_test_labels\n",
    "    yB = y\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XB,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_B,yB_test,classifierA_oob_score_,classifierB_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprB, tprB, thresholds = roc_curve(yB_test, probas_B[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucB = auc(fprB, tprB)\n",
    "        out.append([roc_aucA,roc_aucB,classifierA_oob_score_,classifierB_oob_score_])\n",
    "    out21 = np.array(out)\n",
    "\n",
    "    # Generate feature matrix for SSP and CLINICAL\n",
    "    XB = np.hstack((X1,X2))\n",
    "    XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "    XB_test = np.hstack((X1_test,X2_test))\n",
    "    XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XB,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_B,yB_test,classifierA_oob_score_,classifierB_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprB, tprB, thresholds = roc_curve(yB_test, probas_B[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucB = auc(fprB, tprB)\n",
    "        out.append([roc_aucA,roc_aucB,classifierA_oob_score_,classifierB_oob_score_])\n",
    "    out31 = np.array(out)\n",
    "\n",
    "    # Compute statistics\n",
    "    AUC1 = np.mean(out21[:,0])\n",
    "    OOB1 = np.mean(out21[:,2])\n",
    "    AUC2 = np.mean(out21[:,1])\n",
    "    OOB2 = np.mean(out21[:,3])\n",
    "    AUC3 = np.mean(out31[:,1])\n",
    "    OOB3 = np.mean(out31[:,3])\n",
    "    CI_AUC2_minus_AUC1 = tuple(map(lambda x: np.percentile(out21[:,1] - out21[:,0],x), [2.5, 97.5]))\n",
    "    CI_AUC3_minus_AUC1 = tuple(map(lambda x: np.percentile(out31[:,1] - out31[:,0],x), [2.5, 97.5]))\n",
    "    CI_OOB2_minus_OOB1 = tuple(map(lambda x: np.percentile(out21[:,3] - out21[:,2],x), [2.5, 97.5]))\n",
    "    CI_OOB3_minus_OOB1 = tuple(map(lambda x: np.percentile(out31[:,3] - out31[:,2],x), [2.5, 97.5]))\n",
    "\n",
    "\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [variables_list,AUC1,OOB1,'%s+SSP'%(variables_list), AUC2, OOB2, CI_AUC2_minus_AUC1, CI_OOB2_minus_OOB1],\n",
    "                [variables_list,AUC1,OOB1,'SSP only', AUC3, OOB3, CI_AUC3_minus_AUC1, CI_OOB3_minus_OOB1]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.396286",
     "start_time": "2017-07-20T01:20:58.082Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "columns=['Clinical Variable(s)','CV 5-Fold AUC_1','Out Of Bag (OOB1) Error',\n",
    "         'Quantitative Variables','CV 5-Fold AUC_2','Out Of Bag (OOB2) Error',\n",
    "         'AUC Difference 95% C.I.','OOB Difference 95% C.I.'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Clinical Variable(s)':[],\n",
    "     'CV 5-Fold AUC_1':[],\n",
    "     'Out Of Bag (OOB1) Error':[],\n",
    "     'Quantitative Variables':[],\n",
    "     'CV 5-Fold AUC_2':[],\n",
    "     'Out Of Bag (OOB2) Error':[],\n",
    "     'AUC Difference 95% C.I.':[],\n",
    "     'OOB Difference 95% C.I.':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "OPTIONS = {\n",
    "    1:[np.arange(20),'EEG+MRI+PET'],\n",
    "    2:[np.arange(12),'EEG'],\n",
    "    3:[np.arange(12,14),'MRI'],\n",
    "    4:[np.arange(13,20),'PET'],\n",
    "}\n",
    "\n",
    "for OPTION,(clinical_variable_idx,variables_list) in OPTIONS.items():\n",
    "    # Generate feature matrix for CLINICAL ONLY\n",
    "    XA = X1[:,clinical_variable_idx]\n",
    "    XA_labels = X1_labels[clinical_variable_idx]\n",
    "    yA = y\n",
    "\n",
    "    # Generate feature matrix for SSP alone\n",
    "    XC = X3\n",
    "    XC_labels = X3_labels\n",
    "    XC_test = X3_test\n",
    "    XC_test_labels = X3_test_labels\n",
    "    yC = y\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XC,yC,classifierA,classifierC))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_C,yC_test,classifierA_oob_score_,classifierC_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprC, tprC, thresholds = roc_curve(yC_test, probas_C[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucC = auc(fprC, tprC)\n",
    "        out.append([roc_aucA,roc_aucC,classifierA_oob_score_,classifierC_oob_score_])\n",
    "    out21 = np.array(out)\n",
    "\n",
    "    # Generate feature matrix for SSP and CLINICAL\n",
    "    XC = np.hstack((X1,X3))\n",
    "    XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "    XC_test = np.hstack((X1_test,X3_test))\n",
    "    XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XC,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_C,yC_test,classifierA_oob_score_,classifierC_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprC, tprC, thresholds = roc_curve(yC_test, probas_C[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucC = auc(fprC, tprC)\n",
    "        out.append([roc_aucA,roc_aucC,classifierA_oob_score_,classifierC_oob_score_])\n",
    "    out31 = np.array(out)\n",
    "\n",
    "    # Compute statistics\n",
    "    AUC1 = np.mean(out21[:,0])\n",
    "    OOB1 = np.mean(out21[:,2])\n",
    "    AUC2 = np.mean(out21[:,1])\n",
    "    OOB2 = np.mean(out21[:,3])\n",
    "    AUC3 = np.mean(out31[:,1])\n",
    "    OOB3 = np.mean(out31[:,3])\n",
    "    CI_AUC2_minus_AUC1 = tuple(map(lambda x: np.percentile(out21[:,1] - out21[:,0],x), [2.5, 97.5]))\n",
    "    CI_AUC3_minus_AUC1 = tuple(map(lambda x: np.percentile(out31[:,1] - out31[:,0],x), [2.5, 97.5]))\n",
    "    CI_OOB2_minus_OOB1 = tuple(map(lambda x: np.percentile(out21[:,3] - out21[:,2],x), [2.5, 97.5]))\n",
    "    CI_OOB3_minus_OOB1 = tuple(map(lambda x: np.percentile(out31[:,3] - out31[:,2],x), [2.5, 97.5]))\n",
    "\n",
    "\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [variables_list,AUC1,OOB1,'%s+Asymmetry'%(variables_list), AUC2, OOB2, CI_AUC2_minus_AUC1, CI_OOB2_minus_OOB1],\n",
    "                [variables_list,AUC1,OOB1,'Asymmetry only', AUC3, OOB3, CI_AUC3_minus_AUC1, CI_OOB3_minus_OOB1]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Feature importances (Table 3)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:54:55.648899",
     "start_time": "2017-07-21T19:54:55.474885"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create feature matrix for training and testing\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 5 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "# y[y<outcome_threshold] = 0\n",
    "# y[y>=outcome_threshold] = 1\n",
    "# y_test[y_test<outcome_threshold] = 0\n",
    "# y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "# Run predictions\n",
    "# Generate feature matrix for CLINICAL ONLY\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "XA_test = X1_test\n",
    "XA_test_labels = X1_test_labels\n",
    "yA = y\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "XB_test = np.hstack((X1_test,X2_test))\n",
    "XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "yB = y\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "XC_test = np.hstack((X1_test,X3_test))\n",
    "XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "yC = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T19:55:02.707567",
     "start_time": "2017-07-21T19:54:58.218480"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature Importance</th>\n",
       "      <th>Univariate Odds Ratio per Unit\n",
       " Increase in Seizure Recurrence [95% CI, p]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petclass_S</td>\n",
       "      <td>10.04</td>\n",
       "      <td>0.29 [0.10 - 0.77, 0.016 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eeg_D</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.56 [0.76 - 17.79, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eeg_LTL+</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3.00 [0.72 - 12.90, 0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eeg_RTL+</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.40 [0.05 - 2.59, 0.33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petclass_M</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.36 [1.16 - 10.00, 0.026 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>petclass_R</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.71 [0.32 - 1.60, 0.41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lesional_NL</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.35 [1.04 - 5.39, 0.041 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contra_z_ai_3dssp_Angular Gyrus</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1.89 [1.22 - 3.02, 0.006 **]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>contra_z_3dssp_Angular Gyrus</td>\n",
       "      <td>5.27</td>\n",
       "      <td>1.03 [0.86 - 1.26, 0.79]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ipsi_z_ai_3dssp_Angular Gyrus</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.53 [0.33 - 0.82, 0.006 **]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ipsi_z_ai_3dssp_Rectal Gyrus</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.76 [0.96 - 3.33, 0.073 .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eeg_LTL+</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.00 [0.72 - 12.90, 0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>contra_z_3dssp_Postcentral Gyrus</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.07 [0.90 - 1.32, 0.45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ipsi_z_ai_3dssp_Inferior Temporal Gyrus</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.34 [0.86 - 2.12, 0.20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>contra_z_3dssp_Parahippocampal Gyrus</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.02 [0.95 - 1.10, 0.58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>contra_z_ai_3dssp_Rectal Gyrus</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.57 [0.30 - 1.04, 0.073 .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>contra_z_ai_3dssp_Middle Temporal Gyrus</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.89 [0.58 - 1.34, 0.56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ipsi_z_ai_3dssp_Cingulate Gyrus</td>\n",
       "      <td>2.13</td>\n",
       "      <td>4.08 [1.07 - 15.21, 0.031 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>contra_z_ai_3dssp_Inferior Temporal Gyrus</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.75 [0.47 - 1.17, 0.20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>contra_z_ai_3dssp_Thalamus</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.73 [0.46 - 1.16, 0.18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ipsi_z_3dssp_Subcallosal Gyrus</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.99 [0.89 - 1.09, 0.89]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ipsi_z_ai_3dssp_Middle Temporal Gyrus</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.13 [0.74 - 1.71, 0.56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>contra_z_ai_3dssp_Cingulate Gyrus</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.24 [0.07 - 0.93, 0.031 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>contra_z_3dssp_Posterior Cingulate</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.14 [0.81 - 1.65, 0.47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ipsi_z_3dssp_Middle Frontal Gyrus</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.97 [0.82 - 1.16, 0.73]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>contra_z_3dssp_Subcallosal Gyrus</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97 [0.84 - 1.09, 0.66]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>petclass_M</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.36 [1.16 - 10.00, 0.026 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ipsi_z_3dssp_Superior Frontal Gyrus</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00 [0.85 - 1.20, 0.98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>contra_z_3dssp_Precentral Gyrus</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.04 [0.88 - 1.26, 0.69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>eeg_RTL+</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.40 [0.05 - 2.59, 0.33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>eeg_LTL</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.74 [0.32 - 1.66, 0.46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ipsi_z_3dssp_Inferior Frontal Gyrus</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.93 [0.74 - 1.16, 0.50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ipsi_z_3dssp_Medial Frontal Gyrus</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.99 [0.75 - 1.34, 0.95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lesional_L</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.43 [0.19 - 0.96, 0.041 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>contra_z_3dssp_Rectal Gyrus</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.96 [0.80 - 1.11, 0.58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>eeg_NotAvailable</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.18 [0.13 - 8.64, 0.87]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>contra_z_ai_3dssp_Inferior Parietal Lobule</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.73 [0.47 - 1.13, 0.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ipsi_z_ai_3dssp_Inferior Parietal Lobule</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.36 [0.89 - 2.12, 0.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>contra_z_3dssp_Precuneus</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96 [0.78 - 1.17, 0.64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ipsi_pet_ai_thalamus</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.00 [0.00 - 0.01, 0.003 **]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>contra_pet_ai_thalamus</td>\n",
       "      <td>5.00</td>\n",
       "      <td>189135.55 [78.99 - 691517364.21, 0.003 **]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>petclass_S</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.29 [0.10 - 0.77, 0.016 *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>petclass_R</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.71 [0.32 - 1.60, 0.41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>eeg_LTL+</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.00 [0.72 - 12.90, 0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>eeg_RTL+</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.40 [0.05 - 2.59, 0.33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>eeg_D</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.56 [0.76 - 17.79, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Feature Feature Importance  \\\n",
       "0                                   petclass_S              10.04   \n",
       "1                                        eeg_D               5.28   \n",
       "2                                     eeg_LTL+               4.89   \n",
       "3                                     eeg_RTL+               4.82   \n",
       "4                                   petclass_M               3.61   \n",
       "5                                   petclass_R               2.02   \n",
       "6                                  lesional_NL               1.08   \n",
       "7                                                                   \n",
       "8              contra_z_ai_3dssp_Angular Gyrus               5.55   \n",
       "9                 contra_z_3dssp_Angular Gyrus               5.27   \n",
       "10               ipsi_z_ai_3dssp_Angular Gyrus               4.75   \n",
       "11                ipsi_z_ai_3dssp_Rectal Gyrus               3.10   \n",
       "12                                    eeg_LTL+               3.09   \n",
       "13            contra_z_3dssp_Postcentral Gyrus               3.04   \n",
       "14     ipsi_z_ai_3dssp_Inferior Temporal Gyrus               2.54   \n",
       "15        contra_z_3dssp_Parahippocampal Gyrus               2.50   \n",
       "16              contra_z_ai_3dssp_Rectal Gyrus               2.43   \n",
       "17     contra_z_ai_3dssp_Middle Temporal Gyrus               2.23   \n",
       "18             ipsi_z_ai_3dssp_Cingulate Gyrus               2.13   \n",
       "19   contra_z_ai_3dssp_Inferior Temporal Gyrus               1.98   \n",
       "20                  contra_z_ai_3dssp_Thalamus               1.77   \n",
       "21              ipsi_z_3dssp_Subcallosal Gyrus               1.75   \n",
       "22       ipsi_z_ai_3dssp_Middle Temporal Gyrus               1.74   \n",
       "23           contra_z_ai_3dssp_Cingulate Gyrus               1.48   \n",
       "24          contra_z_3dssp_Posterior Cingulate               1.37   \n",
       "25           ipsi_z_3dssp_Middle Frontal Gyrus               1.30   \n",
       "26            contra_z_3dssp_Subcallosal Gyrus               0.93   \n",
       "27                                  petclass_M               0.83   \n",
       "28         ipsi_z_3dssp_Superior Frontal Gyrus               0.77   \n",
       "29             contra_z_3dssp_Precentral Gyrus               0.60   \n",
       "30                                    eeg_RTL+               0.54   \n",
       "31                                     eeg_LTL               0.42   \n",
       "32         ipsi_z_3dssp_Inferior Frontal Gyrus               0.39   \n",
       "33           ipsi_z_3dssp_Medial Frontal Gyrus               0.36   \n",
       "34                                  lesional_L               0.36   \n",
       "35                 contra_z_3dssp_Rectal Gyrus               0.31   \n",
       "36                            eeg_NotAvailable               0.25   \n",
       "37  contra_z_ai_3dssp_Inferior Parietal Lobule               0.13   \n",
       "38    ipsi_z_ai_3dssp_Inferior Parietal Lobule               0.09   \n",
       "39                    contra_z_3dssp_Precuneus               0.04   \n",
       "40                                                                  \n",
       "41                        ipsi_pet_ai_thalamus               5.73   \n",
       "42                      contra_pet_ai_thalamus               5.00   \n",
       "43                                  petclass_S               3.23   \n",
       "44                                  petclass_R               2.22   \n",
       "45                                    eeg_LTL+               1.96   \n",
       "46                                    eeg_RTL+               1.44   \n",
       "47                                       eeg_D               0.92   \n",
       "48                                                                  \n",
       "\n",
       "   Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]  \n",
       "0                         0.29 [0.10 - 0.77, 0.016 *]                           \n",
       "1                           3.56 [0.76 - 17.79, 0.11]                           \n",
       "2                           3.00 [0.72 - 12.90, 0.13]                           \n",
       "3                            0.40 [0.05 - 2.59, 0.33]                           \n",
       "4                        3.36 [1.16 - 10.00, 0.026 *]                           \n",
       "5                            0.71 [0.32 - 1.60, 0.41]                           \n",
       "6                         2.35 [1.04 - 5.39, 0.041 *]                           \n",
       "7                                                                               \n",
       "8                        1.89 [1.22 - 3.02, 0.006 **]                           \n",
       "9                            1.03 [0.86 - 1.26, 0.79]                           \n",
       "10                       0.53 [0.33 - 0.82, 0.006 **]                           \n",
       "11                        1.76 [0.96 - 3.33, 0.073 .]                           \n",
       "12                          3.00 [0.72 - 12.90, 0.13]                           \n",
       "13                           1.07 [0.90 - 1.32, 0.45]                           \n",
       "14                           1.34 [0.86 - 2.12, 0.20]                           \n",
       "15                           1.02 [0.95 - 1.10, 0.58]                           \n",
       "16                        0.57 [0.30 - 1.04, 0.073 .]                           \n",
       "17                           0.89 [0.58 - 1.34, 0.56]                           \n",
       "18                       4.08 [1.07 - 15.21, 0.031 *]                           \n",
       "19                           0.75 [0.47 - 1.17, 0.20]                           \n",
       "20                           0.73 [0.46 - 1.16, 0.18]                           \n",
       "21                           0.99 [0.89 - 1.09, 0.89]                           \n",
       "22                           1.13 [0.74 - 1.71, 0.56]                           \n",
       "23                        0.24 [0.07 - 0.93, 0.031 *]                           \n",
       "24                           1.14 [0.81 - 1.65, 0.47]                           \n",
       "25                           0.97 [0.82 - 1.16, 0.73]                           \n",
       "26                           0.97 [0.84 - 1.09, 0.66]                           \n",
       "27                       3.36 [1.16 - 10.00, 0.026 *]                           \n",
       "28                           1.00 [0.85 - 1.20, 0.98]                           \n",
       "29                           1.04 [0.88 - 1.26, 0.69]                           \n",
       "30                           0.40 [0.05 - 2.59, 0.33]                           \n",
       "31                           0.74 [0.32 - 1.66, 0.46]                           \n",
       "32                           0.93 [0.74 - 1.16, 0.50]                           \n",
       "33                           0.99 [0.75 - 1.34, 0.95]                           \n",
       "34                        0.43 [0.19 - 0.96, 0.041 *]                           \n",
       "35                           0.96 [0.80 - 1.11, 0.58]                           \n",
       "36                           1.18 [0.13 - 8.64, 0.87]                           \n",
       "37                           0.73 [0.47 - 1.13, 0.16]                           \n",
       "38                           1.36 [0.89 - 2.12, 0.16]                           \n",
       "39                           0.96 [0.78 - 1.17, 0.64]                           \n",
       "40                                                                              \n",
       "41                       0.00 [0.00 - 0.01, 0.003 **]                           \n",
       "42         189135.55 [78.99 - 691517364.21, 0.003 **]                           \n",
       "43                        0.29 [0.10 - 0.77, 0.016 *]                           \n",
       "44                           0.71 [0.32 - 1.60, 0.41]                           \n",
       "45                          3.00 [0.72 - 12.90, 0.13]                           \n",
       "46                           0.40 [0.05 - 2.59, 0.33]                           \n",
       "47                          3.56 [0.76 - 17.79, 0.11]                           \n",
       "48                                                                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "robjects.globalenv['RANDOM_STATE'] = RANDOM_STATE\n",
    "\n",
    "# Generate final form of Table 2\n",
    "columns=[\n",
    "    'Feature',\n",
    "    'Feature Importance',\n",
    "    'Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Feature':[],\n",
    "     'Feature Importance':[],\n",
    "     'Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "for X,y, X_labels in [(XA,yA,XA_labels), (XB,yB,XB_labels), (XC,yC,XC_labels)]:\n",
    "    # Run feature importance (IncMSE) for random forests\n",
    "    robjects.globalenv['X'] = X\n",
    "    robjects.globalenv['y'] = y\n",
    "    summary = robjects.r['summary']\n",
    "\n",
    "    robjects.r('''\n",
    "        set.seed(RANDOM_STATE)\n",
    "        library(randomForest)        \n",
    "        rf <- randomForest(y ~ ., data=X, importance=TRUE)\n",
    "        X_importances <- importance(rf)    \n",
    "    ''')\n",
    "    X_importances = robjects.r['X_importances']\n",
    "    feature_order = np.argsort(-X_importances[:,0])\n",
    "\n",
    "    # Run univariate odds ratio computation\n",
    "    for feature in feature_order:\n",
    "        robjects.globalenv['feature'] = X[:,feature]    \n",
    "        robjects.r('''        \n",
    "            set.seed(RANDOM_STATE)\n",
    "            require(MASS)        \n",
    "            myfit <- polr(as.factor(y) ~ feature, Hess=TRUE)\n",
    "            (ctable <- coef(summary(myfit)))            \n",
    "            p <- pnorm(abs(ctable[,\"t value\"]), lower.tail=FALSE)*2\n",
    "            (ctable <- cbind(ctable, \"p value\" = p))\n",
    "            (ci <- confint(myfit))\n",
    "            myfit_ci <-exp(cbind(OR = coef(myfit), ci))            \n",
    "        ''')\n",
    "        myfit = robjects.r['myfit']\n",
    "        myfit_ci = robjects.r['myfit_ci']\n",
    "        pval = robjects.r['p'][0]\n",
    "        label = X_labels[feature]\n",
    "        try:\n",
    "            label = label.replace(label.split('_')[-1],ssp_labels[int(label.split('_')[-1])])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if X_importances[feature,0] <= 0.0:\n",
    "            continue\n",
    "        \n",
    "        if pval < 0.001:\n",
    "            pval = '%0.3f ***'%pval\n",
    "        elif pval < 0.01:\n",
    "            pval = '%0.3f **'%pval\n",
    "        elif pval < 0.05:\n",
    "            pval = '%0.3f *'%pval\n",
    "        elif pval < 0.1:\n",
    "            pval = '%0.3f .'%pval\n",
    "        else:\n",
    "            pval = '%0.2f'%pval\n",
    "        \n",
    "        results = results.append(\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    [\n",
    "                        label,\n",
    "                        '%0.2f'%X_importances[feature,0], \n",
    "                        '%0.2f [%0.2f - %0.2f, %s]'%(\n",
    "                            myfit_ci[0,0],\n",
    "                            myfit_ci[0,1], myfit_ci[1,1], \n",
    "                            pval\n",
    "                        )\n",
    "                    ]\n",
    "                ],\n",
    "                columns=columns\n",
    "            ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [\n",
    "                    '',\n",
    "                    '', \n",
    "                    ''\n",
    "                ]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "# cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "# results.style.background_gradient(cmap=cm,high=1.0,low=0.0)\n",
    "display(results)\n",
    "results.to_csv('results_Section4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Validation on testing set (Table 4)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.397579",
     "start_time": "2017-07-20T01:21:02.301Z"
    },
    "collapsed": false,
    "level": 7
   },
   "outputs": [],
   "source": [
    "# Create feature matrix for training and testing\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 5 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "# Run predictions\n",
    "# Generate feature matrix for CLINICAL ONLY\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "XA_test = X1_test\n",
    "XA_test_labels = X1_test_labels\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "XB_test = np.hstack((X1_test,X2_test))\n",
    "XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "XC_test = np.hstack((X1_test,X3_test))\n",
    "XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "\n",
    "# Load library in R\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "pROC = importr('pROC')\n",
    "\n",
    "# Train classifier and apply to validation test set\n",
    "classifierA = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsA, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "classifierB = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsB, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "classifierC = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsC, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "\n",
    "probas = classifierA.fit(XA, y).predict_proba(XA_test)\n",
    "predsA = robjects.FloatVector(probas[:,1])\n",
    "labelsA = robjects.IntVector(y_test)\n",
    "probas = classifierB.fit(XB, y).predict_proba(XB_test)\n",
    "predsB = robjects.FloatVector(probas[:,1])\n",
    "labelsB = robjects.IntVector(y_test)\n",
    "probas = classifierC.fit(XC, y).predict_proba(XC_test)\n",
    "predsC = robjects.FloatVector(probas[:,1])\n",
    "labelsC = robjects.IntVector(y_test)\n",
    "\n",
    "\n",
    "# Copy from python workspace to R workspace\n",
    "robjects.globalenv[\"predsA\"] = predsA\n",
    "robjects.globalenv[\"labelsA\"] = labelsA\n",
    "robjects.globalenv[\"predsB\"] = predsB\n",
    "robjects.globalenv[\"labelsB\"] = labelsB\n",
    "robjects.globalenv[\"predsC\"] = predsC\n",
    "robjects.globalenv[\"labelsC\"] = labelsC\n",
    "\n",
    "# Run pROC.roc and pROC.roc.test in R\n",
    "robjects.r('''\n",
    "    predsA<-as.numeric(unlist(predsA))\n",
    "    labelsA<-as.numeric(unlist(labelsA))\n",
    "    predsB<-as.numeric(unlist(predsB))\n",
    "    labelsB<-as.numeric(unlist(labelsB))\n",
    "    predsC<-as.numeric(unlist(predsC))\n",
    "    labelsC<-as.numeric(unlist(labelsC))\n",
    "\n",
    "    library(pROC)\n",
    "    \n",
    "    roc1 <- roc(labelsA, predsA, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc2 <- roc(labelsB, predsB, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc3 <- roc(labelsC, predsC, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc_test12<-roc.test(roc1,roc2)\n",
    "    roc_test13<-roc.test(roc1,roc3)\n",
    "    test_accuracy1<-coords(roc1, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "    test_accuracy2<-coords(roc2, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "    test_accuracy3<-coords(roc3, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "''')\n",
    "\n",
    "# Generate final form of Table 4 \n",
    "columns=['Model','AUC','Accuracy','Sensitivity','Specificity','p-value'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Model':[],\n",
    "     'AUC':[],\n",
    "     'Accuracy':[],\n",
    "     'Sensitivity':[],\n",
    "     'Specificity':[],\n",
    "     'p-value':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "results = results.append(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                'Model 1',\n",
    "                robjects.r[\"roc1\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy1\"][2],\n",
    "                robjects.r[\"test_accuracy1\"][1],\n",
    "                robjects.r[\"test_accuracy1\"][0],\n",
    "                np.nan\n",
    "            ],\n",
    "            [\n",
    "                'Model 2',\n",
    "                robjects.r[\"roc2\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy2\"][2],\n",
    "                robjects.r[\"test_accuracy2\"][1],\n",
    "                robjects.r[\"test_accuracy2\"][0],\n",
    "                robjects.r[\"roc_test12\"].rx2('p.value')[0]\n",
    "            ],\n",
    "            [\n",
    "                'Model 3',\n",
    "                robjects.r[\"roc3\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy3\"][2],\n",
    "                robjects.r[\"test_accuracy3\"][1],\n",
    "                robjects.r[\"test_accuracy3\"][0],\n",
    "                robjects.r[\"roc_test13\"].rx2('p.value')[0]\n",
    "            ]\n",
    "        ],\n",
    "        columns=columns\n",
    "    ),\n",
    "    ignore_index=True\n",
    ")\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0,low=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h1>Prediction of seizure recurrence in Engel I: Engel IA vs. IB-D</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Feature selection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.397988",
     "start_time": "2017-07-20T01:21:04.326Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Selection for Model B\n",
    "\n",
    "# Parameters for feature selection\n",
    "n_repeats = 100\n",
    "num_cv = 5\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "df_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "drop_idx = np.where(np.array(df.outcomeLatest) > 4)[0]\n",
    "df = df.drop(df.index[drop_idx])\n",
    "\n",
    "\n",
    "# Generate feature matrix and target vectors\n",
    "X = np.array(df[df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X_labels = np.array(df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Generate output labels\n",
    "y = np.array(df.outcomeLatest)\n",
    "y[y<2] = 0\n",
    "y[y>=2] = 1\n",
    "\n",
    "\n",
    "all_features = []\n",
    "for iter_id in range(n_repeats):\n",
    "    X_resample, y_resample = sklearn.utils.resample(X,y,n_samples=int(0.7*X.shape[0]),replace=False, random_state=RANDOM_STATE)\n",
    "    fdr = SelectKBest(f_classif,k=int(n_repeats/2))\n",
    "    fdr.fit(X_resample, y_resample)\n",
    "    for index in fdr.get_support(indices=True):\n",
    "        all_features.append(index)\n",
    "all_features =  np.sort(all_features)\n",
    "\n",
    "ft_counts = {}\n",
    "for ft in all_features:\n",
    "    try:\n",
    "        ft_counts[ft] += 1\n",
    "    except KeyError:\n",
    "        ft_counts[ft] = 1\n",
    "SSP_best_features1 = []\n",
    "for ft,ft_count in ft_counts.items():\n",
    "    if ft_count > n_repeats/2:\n",
    "        SSP_best_features1.append(ft)\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=RANDOM_STATE)\n",
    "selector = RFECV(estimator, step=1, cv=num_cv)\n",
    "selector = selector.fit(X,y)\n",
    "SSP_best_features2 = np.where(selector.support_)[0]\n",
    "\n",
    "SSP_features = list(set(SSP_best_features1) & set(SSP_best_features2))\n",
    "print sorted(SSP_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.398400",
     "start_time": "2017-07-20T01:21:05.224Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Selection for Model C\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "df_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "drop_idx = np.where(np.array(df.outcomeLatest) > 4)[0]\n",
    "df = df.drop(df.index[drop_idx])\n",
    "\n",
    "# Generate feature matrix and target vectors\n",
    "X = np.array(df[df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X_labels = np.array(df.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Generate output labels\n",
    "y = np.array(df.outcomeLatest)\n",
    "y[y<2] = 0\n",
    "y[y>=2] = 1\n",
    "\n",
    "all_features = []\n",
    "for iter_id in range(n_repeats):\n",
    "    X_resample, y_resample = sklearn.utils.resample(X,y,n_samples=int(0.7*X.shape[0]),replace=False, random_state=RANDOM_STATE)\n",
    "    fdr = SelectKBest(f_classif,k=int(n_repeats/2))\n",
    "    fdr.fit(X_resample, y_resample)\n",
    "    for index in fdr.get_support(indices=True):\n",
    "        all_features.append(index)\n",
    "all_features =  np.sort(all_features)\n",
    "\n",
    "ft_counts = {}\n",
    "for ft in all_features:\n",
    "    try:\n",
    "        ft_counts[ft] += 1\n",
    "    except KeyError:\n",
    "        ft_counts[ft] = 1\n",
    "ASYMM_best_features1 = []\n",
    "for ft,ft_count in ft_counts.items():\n",
    "    if ft_count > n_repeats/2:\n",
    "        ASYMM_best_features1.append(ft)\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=RANDOM_STATE)\n",
    "selector = RFECV(estimator, step=1, cv=num_cv)\n",
    "selector = selector.fit(X,y)\n",
    "ASYMM_best_features2 = np.where(selector.support_)[0]\n",
    "\n",
    "ASYMM_features = list(set(ASYMM_best_features1) & set(ASYMM_best_features2))\n",
    "print sorted(ASYMM_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T16:23:48.283553",
     "start_time": "2017-07-21T16:23:48.278414"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SSP_features = [1, 2, 5, 8, 9, 12, 19, 22, 29, 30, 32, 33, 37, 38, 39, 40, 41, 51, 52, 58, 60, 64, 68, 78, 80, 84, 85, 88, 91, 94, 98, 102, 104, 106, 108, 109, 113, 114, 115, 116, 117, 118, 127, 128, 134, 136, 140, 141]\n",
    "ASYMM_features = [12, 25, 27, 34, 42, 54, 73, 75, 77, 79, 88, 217, 219, 226, 234, 246, 250, 263, 265, 267, 269, 271, 280, 299, 339, 352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T11:34:52.582443",
     "start_time": "2017-07-21T11:34:52.579929"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(SSP_features), len(ASYMM_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Determine number of estimators</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.398838",
     "start_time": "2017-07-20T01:21:06.854Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "drop_idx = np.where(np.array(dfA.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfA_test.outcomeLatest) > 4)[0]\n",
    "dfA = dfA.drop(dfA.index[drop_idx])\n",
    "dfA_test = dfA_test.drop(dfA_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "drop_idx = np.where(np.array(dfB.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfB_test.outcomeLatest) > 4)[0]\n",
    "dfB = dfB.drop(dfB.index[drop_idx])\n",
    "dfB_test = dfB_test.drop(dfB_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "drop_idx = np.where(np.array(dfC.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfC_test.outcomeLatest) > 4)[0]\n",
    "dfC = dfC.drop(dfC.index[drop_idx])\n",
    "dfC_test = dfC_test.drop(dfC_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "yA = y\n",
    "\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "yB = y\n",
    "\n",
    "yC = y\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "\n",
    "\n",
    "min_estimators = 15\n",
    "max_estimators = 1000\n",
    "\n",
    "clfA = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfA.set_params(n_estimators=i)\n",
    "    clfA.fit(XA,yA)\n",
    "    oob_error = 1-clfA.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsA = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "clfB = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfB.set_params(n_estimators=i)\n",
    "    clfB.fit(XB,yB)\n",
    "    oob_error = 1-clfB.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsB = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "clfC = RandomForestClassifier(warm_start=True, max_features=None, \n",
    "                             oob_score=True, max_depth=max_depth, \n",
    "                             random_state=RANDOM_STATE)\n",
    "error_rate = []\n",
    "for i in range(min_estimators, max_estimators+1):\n",
    "    clfC.set_params(n_estimators=i)\n",
    "    clfC.fit(XC,yC)\n",
    "    oob_error = 1-clfC.oob_score_\n",
    "    error_rate.append((i, oob_error))\n",
    "error_rate = np.array(error_rate)\n",
    "plt.plot(error_rate[:,0], error_rate[:,1])\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.title('OOB Error versus Number of Estimators for Clinical Only')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error rate')\n",
    "plt.show()\n",
    "nest = error_rate[:,0] \n",
    "err = error_rate[:,1]\n",
    "n_estimatorsC = int(nest[np.where(err == np.min(err))[0][0]])\n",
    "\n",
    "\n",
    "print n_estimatorsA, n_estimatorsB, n_estimatorsC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Measure corss-validation scores</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.399258",
     "start_time": "2017-07-20T01:21:07.452Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "classifierA = RandomForestClassifier(n_estimators=n_estimatorsA, max_depth=max_depth, random_state=RANDOM_STATE,oob_score=True)\n",
    "classifierB = RandomForestClassifier(n_estimators=n_estimatorsB, max_depth=max_depth, random_state=RANDOM_STATE, oob_score=True)\n",
    "classifierC = RandomForestClassifier(n_estimators=n_estimatorsC, max_depth=max_depth, random_state=RANDOM_STATE, oob_score=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=NUM_BOOTSTRAPS, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print 'Generating feature matrices ...'\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "drop_idx = np.where(np.array(dfA.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfA_test.outcomeLatest) > 4)[0]\n",
    "dfA = dfA.drop(dfA.index[drop_idx])\n",
    "dfA_test = dfA_test.drop(dfA_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "drop_idx = np.where(np.array(dfB.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfB_test.outcomeLatest) > 4)[0]\n",
    "dfB = dfB.drop(dfB.index[drop_idx])\n",
    "dfB_test = dfB_test.drop(dfB_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "drop_idx = np.where(np.array(dfC.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfC_test.outcomeLatest) > 4)[0]\n",
    "dfC = dfC.drop(dfC.index[drop_idx])\n",
    "dfC_test = dfC_test.drop(dfC_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.399674",
     "start_time": "2017-07-20T01:21:37.772Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['Clinical Variable(s)','CV 5-Fold AUC_1','Out Of Bag (OOB1) Error',\n",
    "         'Quantitative Variables','CV 5-Fold AUC_2','Out Of Bag (OOB2) Error',\n",
    "         'AUC Difference 95% C.I.','OOB Difference 95% C.I.'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Clinical Variable(s)':[],\n",
    "     'CV 5-Fold AUC_1':[],\n",
    "     'Out Of Bag (OOB1) Error':[],\n",
    "     'Quantitative Variables':[],\n",
    "     'CV 5-Fold AUC_2':[],\n",
    "     'Out Of Bag (OOB2) Error':[],\n",
    "     'AUC Difference 95% C.I.':[],\n",
    "     'OOB Difference 95% C.I.':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "OPTIONS = {\n",
    "    1:[np.arange(20),'EEG+MRI+PET'],\n",
    "    2:[np.arange(12),'EEG'],\n",
    "    3:[np.arange(12,14),'MRI'],\n",
    "    4:[np.arange(13,20),'PET'],\n",
    "}\n",
    "\n",
    "for OPTION,(clinical_variable_idx,variables_list) in OPTIONS.items():\n",
    "    # Generate feature matrix for CLINICAL ONLY\n",
    "    XA = X1[:,clinical_variable_idx]\n",
    "    XA_labels = X1_labels[clinical_variable_idx]\n",
    "    yA = y\n",
    "\n",
    "    # Generate feature matrix for SSP alone\n",
    "    XB = X2\n",
    "    XB_labels = X2_labels\n",
    "    XB_test = X2_test\n",
    "    XB_test_labels = X2_test_labels\n",
    "    yB = y\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XB,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_B,yB_test,classifierA_oob_score_,classifierB_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprB, tprB, thresholds = roc_curve(yB_test, probas_B[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucB = auc(fprB, tprB)\n",
    "        out.append([roc_aucA,roc_aucB,classifierA_oob_score_,classifierB_oob_score_])\n",
    "    out21 = np.array(out)\n",
    "\n",
    "    # Generate feature matrix for SSP and CLINICAL\n",
    "    XB = np.hstack((X1,X2))\n",
    "    XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "    XB_test = np.hstack((X1_test,X2_test))\n",
    "    XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XB,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_B,yB_test,classifierA_oob_score_,classifierB_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprB, tprB, thresholds = roc_curve(yB_test, probas_B[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucB = auc(fprB, tprB)\n",
    "        out.append([roc_aucA,roc_aucB,classifierA_oob_score_,classifierB_oob_score_])\n",
    "    out31 = np.array(out)\n",
    "\n",
    "    # Compute statistics\n",
    "    AUC1 = np.mean(out21[:,0])\n",
    "    OOB1 = np.mean(out21[:,2])\n",
    "    AUC2 = np.mean(out21[:,1])\n",
    "    OOB2 = np.mean(out21[:,3])\n",
    "    AUC3 = np.mean(out31[:,1])\n",
    "    OOB3 = np.mean(out31[:,3])\n",
    "    CI_AUC2_minus_AUC1 = tuple(map(lambda x: np.percentile(out21[:,1] - out21[:,0],x), [2.5, 97.5]))\n",
    "    CI_AUC3_minus_AUC1 = tuple(map(lambda x: np.percentile(out31[:,1] - out31[:,0],x), [2.5, 97.5]))\n",
    "    CI_OOB2_minus_OOB1 = tuple(map(lambda x: np.percentile(out21[:,3] - out21[:,2],x), [2.5, 97.5]))\n",
    "    CI_OOB3_minus_OOB1 = tuple(map(lambda x: np.percentile(out31[:,3] - out31[:,2],x), [2.5, 97.5]))\n",
    "\n",
    "\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [variables_list,AUC1,OOB1,'%s+SSP'%(variables_list), AUC2, OOB2, CI_AUC2_minus_AUC1, CI_OOB2_minus_OOB1],\n",
    "                [variables_list,AUC1,OOB1,'SSP only', AUC3, OOB3, CI_AUC3_minus_AUC1, CI_OOB3_minus_OOB1]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.400108",
     "start_time": "2017-07-20T01:21:38.547Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['Clinical Variable(s)','CV 5-Fold AUC_1','Out Of Bag (OOB1) Error',\n",
    "         'Quantitative Variables','CV 5-Fold AUC_2','Out Of Bag (OOB2) Error',\n",
    "         'AUC Difference 95% C.I.','OOB Difference 95% C.I.'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Clinical Variable(s)':[],\n",
    "     'CV 5-Fold AUC_1':[],\n",
    "     'Out Of Bag (OOB1) Error':[],\n",
    "     'Quantitative Variables':[],\n",
    "     'CV 5-Fold AUC_2':[],\n",
    "     'Out Of Bag (OOB2) Error':[],\n",
    "     'AUC Difference 95% C.I.':[],\n",
    "     'OOB Difference 95% C.I.':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "OPTIONS = {\n",
    "    1:[np.arange(20),'EEG+MRI+PET'],\n",
    "    2:[np.arange(12),'EEG'],\n",
    "    3:[np.arange(12,14),'MRI'],\n",
    "    4:[np.arange(13,20),'PET'],\n",
    "}\n",
    "\n",
    "for OPTION,(clinical_variable_idx,variables_list) in OPTIONS.items():\n",
    "    # Generate feature matrix for CLINICAL ONLY\n",
    "    XA = X1[:,clinical_variable_idx]\n",
    "    XA_labels = X1_labels[clinical_variable_idx]\n",
    "    yA = y\n",
    "\n",
    "    # Generate feature matrix for SSP alone\n",
    "    XC = X3\n",
    "    XC_labels = X3_labels\n",
    "    XC_test = X3_test\n",
    "    XC_test_labels = X3_test_labels\n",
    "    yC = y\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XC,yC,classifierA,classifierC))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_C,yC_test,classifierA_oob_score_,classifierC_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprC, tprC, thresholds = roc_curve(yC_test, probas_C[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucC = auc(fprC, tprC)\n",
    "        out.append([roc_aucA,roc_aucC,classifierA_oob_score_,classifierC_oob_score_])\n",
    "    out21 = np.array(out)\n",
    "\n",
    "    # Generate feature matrix for SSP and CLINICAL\n",
    "    XC = np.hstack((X1,X3))\n",
    "    XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "    XC_test = np.hstack((X1_test,X3_test))\n",
    "    XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "\n",
    "    # Generate bootstrap jobs\n",
    "    jobs = []\n",
    "    out = []\n",
    "    for job_iter,(train, test) in enumerate(sss.split(XA,yA)):\n",
    "        jobs.append((job_iter,train,test,XA,yA,XC,yB,classifierA,classifierB))\n",
    "    # Run all jobs\n",
    "    return_list = pool.map(_helper,jobs)\n",
    "    # Compute OOB/AUC for bootstraps\n",
    "    for res in return_list:\n",
    "        probas_A,yA_test,probas_C,yC_test,classifierA_oob_score_,classifierC_oob_score_ = res\n",
    "        fprA, tprA, thresholds = roc_curve(yA_test, probas_A[:, 1])\n",
    "        fprC, tprC, thresholds = roc_curve(yC_test, probas_C[:, 1])\n",
    "        roc_aucA = auc(fprA, tprA)\n",
    "        roc_aucC = auc(fprC, tprC)\n",
    "        out.append([roc_aucA,roc_aucC,classifierA_oob_score_,classifierC_oob_score_])\n",
    "    out31 = np.array(out)\n",
    "\n",
    "    # Compute statistics\n",
    "    AUC1 = np.mean(out21[:,0])\n",
    "    OOB1 = np.mean(out21[:,2])\n",
    "    AUC2 = np.mean(out21[:,1])\n",
    "    OOB2 = np.mean(out21[:,3])\n",
    "    AUC3 = np.mean(out31[:,1])\n",
    "    OOB3 = np.mean(out31[:,3])\n",
    "    CI_AUC2_minus_AUC1 = tuple(map(lambda x: np.percentile(out21[:,1] - out21[:,0],x), [2.5, 97.5]))\n",
    "    CI_AUC3_minus_AUC1 = tuple(map(lambda x: np.percentile(out31[:,1] - out31[:,0],x), [2.5, 97.5]))\n",
    "    CI_OOB2_minus_OOB1 = tuple(map(lambda x: np.percentile(out21[:,3] - out21[:,2],x), [2.5, 97.5]))\n",
    "    CI_OOB3_minus_OOB1 = tuple(map(lambda x: np.percentile(out31[:,3] - out31[:,2],x), [2.5, 97.5]))\n",
    "\n",
    "\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [variables_list,AUC1,OOB1,'%s+Asymmetry'%(variables_list), AUC2, OOB2, CI_AUC2_minus_AUC1, CI_OOB2_minus_OOB1],\n",
    "                [variables_list,AUC1,OOB1,'Asymmetry only', AUC3, OOB3, CI_AUC3_minus_AUC1, CI_OOB3_minus_OOB1]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Feature improtances (Table 3)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T16:25:51.340734",
     "start_time": "2017-07-21T16:25:51.086043"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "drop_idx = np.where(np.array(dfA.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfA_test.outcomeLatest) > 4)[0]\n",
    "dfA = dfA.drop(dfA.index[drop_idx])\n",
    "dfA_test = dfA_test.drop(dfA_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "drop_idx = np.where(np.array(dfB.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfB_test.outcomeLatest) > 4)[0]\n",
    "dfB = dfB.drop(dfB.index[drop_idx])\n",
    "dfB_test = dfB_test.drop(dfB_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "drop_idx = np.where(np.array(dfC.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfC_test.outcomeLatest) > 4)[0]\n",
    "dfC = dfC.drop(dfC.index[drop_idx])\n",
    "dfC_test = dfC_test.drop(dfC_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "# y[y<outcome_threshold] = 0\n",
    "# y[y>=outcome_threshold] = 1\n",
    "# y_test[y_test<outcome_threshold] = 0\n",
    "# y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "# Run predictions\n",
    "# Generate feature matrix for CLINICAL ONLY\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "XA_test = X1_test\n",
    "XA_test_labels = X1_test_labels\n",
    "yA = y\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "XB_test = np.hstack((X1_test,X2_test))\n",
    "XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "yB = y\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "XC_test = np.hstack((X1_test,X3_test))\n",
    "XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "yC = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T16:25:57.203907",
     "start_time": "2017-07-21T16:25:56.634768"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robjects.globalenv['RANDOM_STATE'] = RANDOM_STATE\n",
    "\n",
    "# Generate final form of Table 2\n",
    "columns=[\n",
    "    'Feature',\n",
    "    'Feature Importance',\n",
    "    'Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Feature':[],\n",
    "     'Feature Importance':[],\n",
    "     'Univariate Odds Ratio per Unit\\n Increase in Seizure Recurrence [95% CI, p]':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "for X,y, X_labels in [(XA,yA,XA_labels), (XB,yB,XB_labels), (XC,yC,XC_labels)]:\n",
    "    # Run feature importance (IncMSE) for random forests\n",
    "    robjects.globalenv['X'] = X\n",
    "    robjects.globalenv['y'] = y\n",
    "    summary = robjects.r['summary']\n",
    "\n",
    "    robjects.r('''\n",
    "        set.seed(RANDOM_STATE)\n",
    "        library(randomForest)        \n",
    "        rf <- randomForest(y ~ ., data=X, importance=TRUE)\n",
    "        X_importances <- importance(rf)    \n",
    "    ''')\n",
    "    X_importances = robjects.r['X_importances']\n",
    "    feature_order = np.argsort(-X_importances[:,0])\n",
    "\n",
    "    # Run univariate odds ratio computation\n",
    "    for feature in feature_order:\n",
    "        robjects.globalenv['feature'] = X[:,feature]    \n",
    "        robjects.r('''        \n",
    "            set.seed(RANDOM_STATE)\n",
    "            require(MASS)        \n",
    "            myfit <- polr(as.factor(y) ~ feature, Hess=TRUE)\n",
    "            (ctable <- coef(summary(myfit)))            \n",
    "            p <- pnorm(abs(ctable[,\"t value\"]), lower.tail=FALSE)*2\n",
    "            (ctable <- cbind(ctable, \"p value\" = p))\n",
    "            (ci <- confint(myfit))\n",
    "            myfit_ci <-exp(cbind(OR = coef(myfit), ci))            \n",
    "        ''')\n",
    "        myfit = robjects.r['myfit']\n",
    "        myfit_ci = robjects.r['myfit_ci']\n",
    "        pval = robjects.r['p'][0]\n",
    "        label = X_labels[feature]\n",
    "        try:\n",
    "            label = label.replace(label.split('_')[-1],ssp_labels[int(label.split('_')[-1])])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if X_importances[feature,0] <= 0.0:\n",
    "            continue\n",
    "        \n",
    "        if pval < 0.001:\n",
    "            pval = '%0.3f ***'%pval\n",
    "        elif pval < 0.01:\n",
    "            pval = '%0.3f **'%pval\n",
    "        elif pval < 0.05:\n",
    "            pval = '%0.3f *'%pval\n",
    "        elif pval < 0.1:\n",
    "            pval = '%0.3f .'%pval\n",
    "        else:\n",
    "            pval = '%0.2f'%pval\n",
    "        \n",
    "        results = results.append(\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    [\n",
    "                        label,\n",
    "                        '%0.2f'%X_importances[feature,0], \n",
    "                        '%0.2f [%0.2f - %0.2f, %s]'%(\n",
    "                            myfit_ci[0,0],\n",
    "                            myfit_ci[0,1], myfit_ci[1,1], \n",
    "                            pval\n",
    "                        )\n",
    "                    ]\n",
    "                ],\n",
    "                columns=columns\n",
    "            ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "    results = results.append(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [\n",
    "                    '',\n",
    "                    '', \n",
    "                    ''\n",
    "                ]\n",
    "            ],\n",
    "            columns=columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "# cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "# results.style.background_gradient(cmap=cm,high=1.0,low=0.0)\n",
    "display(results)\n",
    "results.to_csv('results_Section5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "<h2>Validation on testing set (Table 4)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T22:06:27.401445",
     "start_time": "2017-07-20T01:21:42.382Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create feature matrix for training and testing\n",
    "# Load data for CLINICAL ONLY\n",
    "dfA = pd.read_csv('../data/qPET_feature_matrix_clinical_only.csv')\n",
    "dfA_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_only.csv')\n",
    "drop_idx = np.where(np.array(dfA.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfA_test.outcomeLatest) > 4)[0]\n",
    "dfA = dfA.drop(dfA.index[drop_idx])\n",
    "dfA_test = dfA_test.drop(dfA_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X1 = np.array(dfA[dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_labels = np.array(dfA.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "# Testing\n",
    "X1_test = np.array(dfA_test[dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X1_test_labels = np.array(dfA_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "\n",
    "# Load data for SSP ONLY\n",
    "dfB = pd.read_csv('../data/qPET_feature_matrix_clinical_3dssp.csv')\n",
    "dfB_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_3dssp.csv')\n",
    "drop_idx = np.where(np.array(dfB.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfB_test.outcomeLatest) > 4)[0]\n",
    "dfB = dfB.drop(dfB.index[drop_idx])\n",
    "dfB_test = dfB_test.drop(dfB_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training and testing data\n",
    "# Training\n",
    "X2 = np.array(dfB[dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_labels = np.array(dfB.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2 = X2[:,SSP_features]\n",
    "X2_labels = X2_labels[SSP_features]\n",
    "# Testing\n",
    "X2_test = np.array(dfB_test[dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X2_test_labels = np.array(dfB_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X2_test = X2_test[:,SSP_features]\n",
    "X2_test_labels = X2_test_labels[SSP_features]\n",
    "\n",
    "# Load data for ASYMMETRY ONLY\n",
    "dfC = pd.read_csv('../data/qPET_feature_matrix_clinical_voxel_ai.csv')\n",
    "dfC_test = pd.read_csv('../data/qPET_Validation_feature_matrix_clinical_voxel_ai.csv')\n",
    "drop_idx = np.where(np.array(dfC.outcomeLatest) > 4)[0]\n",
    "drop_test_idx = np.where(np.array(dfC_test.outcomeLatest) > 4)[0]\n",
    "dfC = dfC.drop(dfC.index[drop_idx])\n",
    "dfC_test = dfC_test.drop(dfC_test.index[drop_test_idx])\n",
    "\n",
    "# Generate feature matrix for training testing data\n",
    "# Training\n",
    "X3 = np.array(dfC[dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_labels = np.array(dfC.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3 = X3[:,ASYMM_features]\n",
    "X3_labels = X3_labels[ASYMM_features]\n",
    "# Testing\n",
    "X3_test = np.array(dfC_test[dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest'])])\n",
    "X3_test_labels = np.array(dfC_test.columns.difference(['Unnamed: 0','id','outcome12','outcome24','outcome6','outcomeLatest']))\n",
    "X3_test = X3_test[:,ASYMM_features]\n",
    "X3_test_labels = X3_test_labels[ASYMM_features]\n",
    "\n",
    "# Generate outcome variable\n",
    "outcome_threshold = 2 # i.e. Engel 1B\n",
    "y = np.array(dfA.outcomeLatest)\n",
    "y_test = np.array(dfA_test.outcomeLatest)\n",
    "y[y<outcome_threshold] = 0\n",
    "y[y>=outcome_threshold] = 1\n",
    "y_test[y_test<outcome_threshold] = 0\n",
    "y_test[y_test>=outcome_threshold] = 1\n",
    "\n",
    "# Run predictions\n",
    "# Generate feature matrix for CLINICAL ONLY\n",
    "XA = X1\n",
    "XA_labels = X1_labels\n",
    "XA_test = X1_test\n",
    "XA_test_labels = X1_test_labels\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XB = np.hstack((X1,X2))\n",
    "XB_labels = np.hstack((X1_labels,X2_labels))\n",
    "XB_test = np.hstack((X1_test,X2_test))\n",
    "XB_test_labels = np.hstack((X1_test_labels,X2_test_labels))\n",
    "\n",
    "# Generate feature matrix for SSP and CLINICAL\n",
    "XC = np.hstack((X1,X3))\n",
    "XC_labels = np.hstack((X1_labels,X3_labels))\n",
    "XC_test = np.hstack((X1_test,X3_test))\n",
    "XC_test_labels = np.hstack((X1_test_labels,X3_test_labels))\n",
    "\n",
    "# Load library in R\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "pROC = importr('pROC')\n",
    "\n",
    "# Train classifier and apply to validation test set\n",
    "classifierA = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsA, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "classifierB = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsB, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "classifierC = RandomForestClassifier(\n",
    "    n_estimators=n_estimatorsC, \n",
    "    max_depth=max_depth, \n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True)\n",
    "\n",
    "probas = classifierA.fit(XA, y).predict_proba(XA_test)\n",
    "predsA = robjects.FloatVector(probas[:,1])\n",
    "labelsA = robjects.IntVector(y_test)\n",
    "probas = classifierB.fit(XB, y).predict_proba(XB_test)\n",
    "predsB = robjects.FloatVector(probas[:,1])\n",
    "labelsB = robjects.IntVector(y_test)\n",
    "probas = classifierC.fit(XC, y).predict_proba(XC_test)\n",
    "predsC = robjects.FloatVector(probas[:,1])\n",
    "labelsC = robjects.IntVector(y_test)\n",
    "\n",
    "\n",
    "# Copy from python workspace to R workspace\n",
    "robjects.globalenv[\"predsA\"] = predsA\n",
    "robjects.globalenv[\"labelsA\"] = labelsA\n",
    "robjects.globalenv[\"predsB\"] = predsB\n",
    "robjects.globalenv[\"labelsB\"] = labelsB\n",
    "robjects.globalenv[\"predsC\"] = predsC\n",
    "robjects.globalenv[\"labelsC\"] = labelsC\n",
    "\n",
    "# Run pROC.roc and pROC.roc.test in R\n",
    "robjects.r('''\n",
    "    predsA<-as.numeric(unlist(predsA))\n",
    "    labelsA<-as.numeric(unlist(labelsA))\n",
    "    predsB<-as.numeric(unlist(predsB))\n",
    "    labelsB<-as.numeric(unlist(labelsB))\n",
    "    predsC<-as.numeric(unlist(predsC))\n",
    "    labelsC<-as.numeric(unlist(labelsC))\n",
    "\n",
    "    library(pROC)\n",
    "    \n",
    "    roc1 <- roc(labelsA, predsA, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc2 <- roc(labelsB, predsB, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc3 <- roc(labelsC, predsC, percent=FALSE, \n",
    "    smooth=TRUE, ci=TRUE, boot.n=100, ci.alpha=0.95, \n",
    "    stratified=TRUE,plot=FALSE,grid=FALSE,print.auc=FALSE, show.thres=TRUE, col='red')\n",
    "    roc_test12<-roc.test(roc1,roc2)\n",
    "    roc_test13<-roc.test(roc1,roc3)\n",
    "    test_accuracy1<-coords(roc1, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "    test_accuracy2<-coords(roc2, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "    test_accuracy3<-coords(roc3, \"best\", ret=c(\"specificity\",\"sensitivity\",\"accuracy\"), best.method=c(\"youden\",\"closest.topleft\"));\n",
    "''')\n",
    "\n",
    "# Generate final form of Table 4 \n",
    "columns=['Model','AUC','Accuracy','Sensitivity','Specificity','p-value'\n",
    "        ]\n",
    "results = pd.DataFrame(\n",
    "    {'Model':[],\n",
    "     'AUC':[],\n",
    "     'Accuracy':[],\n",
    "     'Sensitivity':[],\n",
    "     'Specificity':[],\n",
    "     'p-value':[]\n",
    "             },\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "results = results.append(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                'Model 1',\n",
    "                robjects.r[\"roc1\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy1\"][2],\n",
    "                robjects.r[\"test_accuracy1\"][1],\n",
    "                robjects.r[\"test_accuracy1\"][0],\n",
    "                np.nan\n",
    "            ],\n",
    "            [\n",
    "                'Model 2',\n",
    "                robjects.r[\"roc2\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy2\"][2],\n",
    "                robjects.r[\"test_accuracy2\"][1],\n",
    "                robjects.r[\"test_accuracy2\"][0],\n",
    "                robjects.r[\"roc_test12\"].rx2('p.value')[0]\n",
    "            ],\n",
    "            [\n",
    "                'Model 3',\n",
    "                robjects.r[\"roc3\"].rx2('auc')[0],\n",
    "                robjects.r[\"test_accuracy3\"][2],\n",
    "                robjects.r[\"test_accuracy3\"][1],\n",
    "                robjects.r[\"test_accuracy3\"][0],\n",
    "                robjects.r[\"roc_test13\"].rx2('p.value')[0]\n",
    "            ]\n",
    "        ],\n",
    "        columns=columns\n",
    "    ),\n",
    "    ignore_index=True\n",
    ")\n",
    "cm = sns.light_palette(\"green\",as_cmap=True)\n",
    "results.style.background_gradient(cmap=cm,high=1.0,low=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
